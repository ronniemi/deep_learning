{
  "cells": [
    {
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true
      },
      "cell_type": "code",
      "source": "# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nfrom keras.models import Model\nfrom keras.layers import *\nfrom keras.callbacks import *\nfrom keras.regularizers import l2\nfrom keras.optimizers import *\nfrom keras.utils import to_categorical\nimport datetime\nfrom sklearn.preprocessing import LabelEncoder\nimport gc\nfrom sklearn.model_selection import train_test_split\nimport lightgbm as lgb\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.model_selection import KFold,StratifiedKFold\nfrom keras import backend as K\nfrom sklearn.model_selection import KFold\n\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Using TensorFlow backend.\n",
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": "['train.csv', 'merchants.csv', 'sample_submission.csv', 'test.csv', 'historical_transactions.csv', 'Data_Dictionary.xlsx', 'new_merchant_transactions.csv']\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "_uuid": "86cae6aa917478a27cd397d7dcc949447e696e5e"
      },
      "cell_type": "markdown",
      "source": "# Define global functions"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "4f4a12768f717d1dbf1671bdae5021816b60dd1e"
      },
      "cell_type": "code",
      "source": "# define function to reduce memory usage\ndef reduce_mem_usage(df, verbose=True):\n    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n    start_mem = df.memory_usage().sum() / 1024**2    \n    for col in df.columns:\n        col_type = df[col].dtypes\n        if col_type in numerics:\n            c_min = df[col].min()\n            c_max = df[col].max()\n            if str(col_type)[:3] == 'int':\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)  \n            else:\n                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n                    df[col] = df[col].astype(np.float16)\n                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    df[col] = df[col].astype(np.float64)    \n    end_mem = df.memory_usage().sum() / 1024**2\n    if verbose: print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(end_mem, 100 * (start_mem - end_mem) / start_mem))\n    return df\n\n# define function that calaculate RMSE\ndef root_mean_squared_error(y_true, y_pred):\n        return K.sqrt(K.mean(K.square(y_pred - y_true)))",
      "execution_count": 2,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "d9f7ce14f675a7fb562e70187ca409b14db27d3e"
      },
      "cell_type": "markdown",
      "source": "# Read data"
    },
    {
      "metadata": {
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "trusted": true,
        "scrolled": false
      },
      "cell_type": "code",
      "source": "train_set = pd.read_csv(\"../input/train.csv\", parse_dates=[\"first_active_month\"])\ntest_set = pd.read_csv(\"../input/test.csv\", parse_dates=[\"first_active_month\"])\nhistory_trx = pd.read_csv(\"../input/historical_transactions.csv\", parse_dates=['purchase_date'])\nnew_trx = pd.read_csv(\"../input/new_merchant_transactions.csv\", parse_dates=['purchase_date'])\n#merchants_set = pd.read_csv(\"../input/merchants.csv\")\n\nprint(\"shape of train : \",train_set.shape)\nprint(\"shape of test : \",test_set.shape)\nprint(\"shape of history_trx : \",history_trx.shape)\nprint(\"shape of new_trx : \",new_trx.shape)\n#print(\"shape of merchants : \",merchants_set.shape)",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": "shape of train :  (201917, 6)\nshape of test :  (123623, 5)\nshape of history_trx :  (29112361, 14)\nshape of new_trx :  (1963031, 14)\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "_uuid": "4bdb9744aa760f20ff42eef26f9a8e037e4ee955"
      },
      "cell_type": "markdown",
      "source": "# Feature extrection - collect information per card to form card_id profile"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "e1ae4cd8e747a22cd1cc955179713c2a199a1a80"
      },
      "cell_type": "code",
      "source": "# add 'year', 'month', and 'elepsed_time' features to the dataframe\nfor df in [train_set, test_set]:\n    df['year'] = df['first_active_month'].dt.year\n    df['month'] = df['first_active_month'].dt.month\n    df['elapsed_time'] = (datetime.date(2018, 2, 1) - df['first_active_month'].dt.date).dt.days # 1/2/2018 is the max date in train set\n    \n# create set of columns name that is numeric\nnumeric_col = ['elapsed_time']\n\n# split the train set to features and target\ntarget = train_set['target']\ndel train_set['target']",
      "execution_count": 4,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "531ab3c6752bd71966845bc98cb46c8c194ef322"
      },
      "cell_type": "code",
      "source": "# define aggregation function that collect information from data features to crate profile to each card_id\ndef agg_data_trx(trx_data, col_name):\n    \n    trx_data['authorized_flag'] = trx_data['authorized_flag'].map({'Y':1, 'N':0})\n    \n    trx_data['purchase_month'] = trx_data['purchase_date'].dt.month\n    \n    trx_data['month_diff'] = ((datetime.datetime.today() - trx_data['purchase_date']).dt.days)//30\n    trx_data['month_diff'] += trx_data['month_lag']\n    \n    trx_data = reduce_mem_usage(trx_data)\n    \n    trx_data.loc[:, 'purchase_date'] = pd.DatetimeIndex(trx_data['purchase_date']).astype(np.int64) * 1e-9\n    \n    agg_func = {\n        'merchant_id': ['nunique'],\n        'merchant_category_id': ['nunique'],\n        'state_id': ['nunique'],\n        'city_id': ['nunique'],\n        'subsector_id': ['nunique'],\n        'purchase_amount': ['sum', 'mean', 'max', 'min', 'std'],\n        'installments': ['sum', 'mean', 'max', 'min', 'std'],\n        'purchase_date': [np.ptp, 'min', 'max'],\n        'month_lag': ['mean', 'max', 'min', 'std'],\n        'month_diff': ['mean']\n    }\n    \n    agg_data = trx_data.groupby(['card_id']).agg(agg_func)\n    agg_data.columns = [col_name + '_' + '_'.join(col).strip() for col in agg_data.columns.values]\n    agg_data.reset_index(inplace=True)\n    \n    df = (trx_data.groupby('card_id').size().reset_index(name=col_name + '_trx_count'))\n    \n    agg_data = pd.merge(df, agg_data, on='card_id', how='left')\n    \n    agg_numeric_col = [col for col in agg_data.columns if col not in ['card_id']]\n    numeric_col.extend(agg_numeric_col)\n    \n    return agg_data\n\nauthorized_trx = history_trx[history_trx['authorized_flag'] == 'Y']\nhistory_trx = history_trx[history_trx['authorized_flag'] == 'N']\n\nhistory_trx_per_card = agg_data_trx(history_trx, 'history')\nauthorized_trx_per_card = agg_data_trx(authorized_trx, 'auto')\nnew_trx_per_card = agg_data_trx(new_trx, 'new')\n\n# merge the new features for each card_id with the 3 basic features in train set and test set\ntrain_set = pd.merge(train_set, history_trx_per_card, on='card_id', how='left')\ntest_set = pd.merge(test_set, history_trx_per_card, on='card_id', how='left')\n\ntrain_set = pd.merge(train_set, authorized_trx_per_card, on='card_id', how='left')\ntest_set = pd.merge(test_set, authorized_trx_per_card, on='card_id', how='left')\n\ntrain_set = pd.merge(train_set, new_trx_per_card, on='card_id', how='left')\ntest_set = pd.merge(test_set, new_trx_per_card, on='card_id', how='left')\n\n# delete unnecessary dataframes to reduce memory usage\ndel history_trx_per_card\ndel new_trx_per_card\ndel authorized_trx_per_card\ngc.collect()\n\n# define the columns that are going to enter to the model\nused_col = train_set.columns\nused_col =  [col for col in used_col if col not in ['card_id', 'first_active_month']]",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Mem. usage decreased to 158.42 Mb (51.5% reduction)\nMem. usage decreased to 1623.26 Mb (52.9% reduction)\nMem. usage decreased to 104.84 Mb (56.2% reduction)\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "903527688cbd7f587fb4d8f2bc7e80d5666a0533"
      },
      "cell_type": "code",
      "source": "train_set.head()",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 6,
          "data": {
            "text/plain": "  first_active_month         ...         new_month_diff_mean\n0         2017-06-01         ...                    9.695652\n1         2017-01-01         ...                   10.833333\n2         2016-08-01         ...                    9.000000\n3         2017-09-01         ...                   10.000000\n4         2017-11-01         ...                    9.833333\n\n[5 rows x 80 columns]",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>first_active_month</th>\n      <th>card_id</th>\n      <th>feature_1</th>\n      <th>feature_2</th>\n      <th>feature_3</th>\n      <th>year</th>\n      <th>month</th>\n      <th>elapsed_time</th>\n      <th>history_trx_count</th>\n      <th>history_merchant_id_nunique</th>\n      <th>history_merchant_category_id_nunique</th>\n      <th>history_state_id_nunique</th>\n      <th>history_city_id_nunique</th>\n      <th>history_subsector_id_nunique</th>\n      <th>history_purchase_amount_sum</th>\n      <th>history_purchase_amount_mean</th>\n      <th>history_purchase_amount_max</th>\n      <th>history_purchase_amount_min</th>\n      <th>history_purchase_amount_std</th>\n      <th>history_installments_sum</th>\n      <th>history_installments_mean</th>\n      <th>history_installments_max</th>\n      <th>history_installments_min</th>\n      <th>history_installments_std</th>\n      <th>history_purchase_date_ptp</th>\n      <th>history_purchase_date_min</th>\n      <th>history_purchase_date_max</th>\n      <th>history_month_lag_mean</th>\n      <th>history_month_lag_max</th>\n      <th>history_month_lag_min</th>\n      <th>history_month_lag_std</th>\n      <th>history_month_diff_mean</th>\n      <th>auto_trx_count</th>\n      <th>auto_merchant_id_nunique</th>\n      <th>auto_merchant_category_id_nunique</th>\n      <th>auto_state_id_nunique</th>\n      <th>auto_city_id_nunique</th>\n      <th>auto_subsector_id_nunique</th>\n      <th>auto_purchase_amount_sum</th>\n      <th>auto_purchase_amount_mean</th>\n      <th>auto_purchase_amount_max</th>\n      <th>auto_purchase_amount_min</th>\n      <th>auto_purchase_amount_std</th>\n      <th>auto_installments_sum</th>\n      <th>auto_installments_mean</th>\n      <th>auto_installments_max</th>\n      <th>auto_installments_min</th>\n      <th>auto_installments_std</th>\n      <th>auto_purchase_date_ptp</th>\n      <th>auto_purchase_date_min</th>\n      <th>auto_purchase_date_max</th>\n      <th>auto_month_lag_mean</th>\n      <th>auto_month_lag_max</th>\n      <th>auto_month_lag_min</th>\n      <th>auto_month_lag_std</th>\n      <th>auto_month_diff_mean</th>\n      <th>new_trx_count</th>\n      <th>new_merchant_id_nunique</th>\n      <th>new_merchant_category_id_nunique</th>\n      <th>new_state_id_nunique</th>\n      <th>new_city_id_nunique</th>\n      <th>new_subsector_id_nunique</th>\n      <th>new_purchase_amount_sum</th>\n      <th>new_purchase_amount_mean</th>\n      <th>new_purchase_amount_max</th>\n      <th>new_purchase_amount_min</th>\n      <th>new_purchase_amount_std</th>\n      <th>new_installments_sum</th>\n      <th>new_installments_mean</th>\n      <th>new_installments_max</th>\n      <th>new_installments_min</th>\n      <th>new_installments_std</th>\n      <th>new_purchase_date_ptp</th>\n      <th>new_purchase_date_min</th>\n      <th>new_purchase_date_max</th>\n      <th>new_month_lag_mean</th>\n      <th>new_month_lag_max</th>\n      <th>new_month_lag_min</th>\n      <th>new_month_lag_std</th>\n      <th>new_month_diff_mean</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2017-06-01</td>\n      <td>C_ID_92a2005557</td>\n      <td>5</td>\n      <td>2</td>\n      <td>1</td>\n      <td>2017</td>\n      <td>6</td>\n      <td>245</td>\n      <td>13.0</td>\n      <td>12.0</td>\n      <td>10.0</td>\n      <td>1.0</td>\n      <td>2.0</td>\n      <td>7.0</td>\n      <td>-8.571723</td>\n      <td>-0.659363</td>\n      <td>-0.431922</td>\n      <td>-0.737892</td>\n      <td>0.098851</td>\n      <td>4.0</td>\n      <td>0.307692</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.480384</td>\n      <td>14254523.0</td>\n      <td>1.500131e+09</td>\n      <td>1.514385e+09</td>\n      <td>-4.461538</td>\n      <td>-2.0</td>\n      <td>-7.0</td>\n      <td>1.664101</td>\n      <td>9.846154</td>\n      <td>247</td>\n      <td>93</td>\n      <td>41</td>\n      <td>3</td>\n      <td>7</td>\n      <td>21</td>\n      <td>-157.375000</td>\n      <td>-0.637207</td>\n      <td>2.257812</td>\n      <td>-0.739258</td>\n      <td>0.216553</td>\n      <td>0</td>\n      <td>0.000000</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.000000</td>\n      <td>20977987.0</td>\n      <td>1.498573e+09</td>\n      <td>1.519551e+09</td>\n      <td>-3.882591</td>\n      <td>0</td>\n      <td>-8</td>\n      <td>2.429155</td>\n      <td>9.825911</td>\n      <td>23.0</td>\n      <td>23.0</td>\n      <td>14.0</td>\n      <td>1.0</td>\n      <td>3.0</td>\n      <td>10.0</td>\n      <td>-13.242188</td>\n      <td>-0.575684</td>\n      <td>-0.296143</td>\n      <td>-0.724609</td>\n      <td>0.135742</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>4742309.0</td>\n      <td>1.520259e+09</td>\n      <td>1.525001e+09</td>\n      <td>1.478261</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>0.510754</td>\n      <td>9.695652</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2017-01-01</td>\n      <td>C_ID_3d0044924f</td>\n      <td>4</td>\n      <td>1</td>\n      <td>0</td>\n      <td>2017</td>\n      <td>1</td>\n      <td>396</td>\n      <td>11.0</td>\n      <td>9.0</td>\n      <td>9.0</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>9.0</td>\n      <td>-1.122886</td>\n      <td>-0.102081</td>\n      <td>1.942838</td>\n      <td>-0.740897</td>\n      <td>0.785906</td>\n      <td>42.0</td>\n      <td>3.818182</td>\n      <td>10.0</td>\n      <td>1.0</td>\n      <td>3.487641</td>\n      <td>25890841.0</td>\n      <td>1.488576e+09</td>\n      <td>1.514467e+09</td>\n      <td>-4.454545</td>\n      <td>-1.0</td>\n      <td>-10.0</td>\n      <td>2.696799</td>\n      <td>10.636364</td>\n      <td>339</td>\n      <td>141</td>\n      <td>57</td>\n      <td>3</td>\n      <td>9</td>\n      <td>24</td>\n      <td>-208.875000</td>\n      <td>-0.616211</td>\n      <td>4.628906</td>\n      <td>-0.742188</td>\n      <td>0.355469</td>\n      <td>501</td>\n      <td>1.477876</td>\n      <td>10</td>\n      <td>-1</td>\n      <td>1.350634</td>\n      <td>33717687.0</td>\n      <td>1.483720e+09</td>\n      <td>1.517438e+09</td>\n      <td>-5.050147</td>\n      <td>0</td>\n      <td>-12</td>\n      <td>3.836969</td>\n      <td>10.876106</td>\n      <td>6.0</td>\n      <td>6.0</td>\n      <td>5.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>4.0</td>\n      <td>-4.355469</td>\n      <td>-0.726074</td>\n      <td>-0.701660</td>\n      <td>-0.739258</td>\n      <td>0.014381</td>\n      <td>6.0</td>\n      <td>1.000000</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.000000</td>\n      <td>4887632.0</td>\n      <td>1.517505e+09</td>\n      <td>1.522393e+09</td>\n      <td>1.500000</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>0.547723</td>\n      <td>10.833333</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2016-08-01</td>\n      <td>C_ID_d639edf6cd</td>\n      <td>2</td>\n      <td>2</td>\n      <td>0</td>\n      <td>2016</td>\n      <td>8</td>\n      <td>549</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>-1.338967</td>\n      <td>-0.669484</td>\n      <td>-0.637515</td>\n      <td>-0.701453</td>\n      <td>0.045211</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>4922885.0</td>\n      <td>1.487878e+09</td>\n      <td>1.492801e+09</td>\n      <td>-11.000000</td>\n      <td>-10.0</td>\n      <td>-12.0</td>\n      <td>1.414214</td>\n      <td>10.000000</td>\n      <td>41</td>\n      <td>13</td>\n      <td>8</td>\n      <td>2</td>\n      <td>5</td>\n      <td>7</td>\n      <td>-27.828125</td>\n      <td>-0.678711</td>\n      <td>-0.145874</td>\n      <td>-0.729980</td>\n      <td>0.089233</td>\n      <td>0</td>\n      <td>0.000000</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.000000</td>\n      <td>35635623.0</td>\n      <td>1.484123e+09</td>\n      <td>1.519759e+09</td>\n      <td>-8.487805</td>\n      <td>0</td>\n      <td>-13</td>\n      <td>3.893083</td>\n      <td>9.853659</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>-0.700195</td>\n      <td>-0.700195</td>\n      <td>-0.700195</td>\n      <td>-0.700195</td>\n      <td>NaN</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>0.0</td>\n      <td>1.524937e+09</td>\n      <td>1.524937e+09</td>\n      <td>2.000000</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>NaN</td>\n      <td>9.000000</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2017-09-01</td>\n      <td>C_ID_186d6a6901</td>\n      <td>4</td>\n      <td>3</td>\n      <td>0</td>\n      <td>2017</td>\n      <td>9</td>\n      <td>153</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>77</td>\n      <td>50</td>\n      <td>25</td>\n      <td>5</td>\n      <td>7</td>\n      <td>13</td>\n      <td>-49.500000</td>\n      <td>-0.642578</td>\n      <td>1.445312</td>\n      <td>-0.740723</td>\n      <td>0.261475</td>\n      <td>84</td>\n      <td>1.090909</td>\n      <td>3</td>\n      <td>-1</td>\n      <td>0.588974</td>\n      <td>13375339.0</td>\n      <td>1.506443e+09</td>\n      <td>1.519818e+09</td>\n      <td>-2.831169</td>\n      <td>0</td>\n      <td>-5</td>\n      <td>1.802065</td>\n      <td>9.792208</td>\n      <td>7.0</td>\n      <td>7.0</td>\n      <td>6.0</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>5.0</td>\n      <td>-4.656250</td>\n      <td>-0.665039</td>\n      <td>-0.566895</td>\n      <td>-0.734375</td>\n      <td>0.065918</td>\n      <td>5.0</td>\n      <td>0.714286</td>\n      <td>1.0</td>\n      <td>-1.0</td>\n      <td>0.755929</td>\n      <td>3625505.0</td>\n      <td>1.520424e+09</td>\n      <td>1.524049e+09</td>\n      <td>1.714286</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>0.487950</td>\n      <td>10.000000</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2017-11-01</td>\n      <td>C_ID_cdbd2c0db2</td>\n      <td>1</td>\n      <td>3</td>\n      <td>0</td>\n      <td>2017</td>\n      <td>11</td>\n      <td>92</td>\n      <td>5.0</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>20.352808</td>\n      <td>4.070562</td>\n      <td>7.193041</td>\n      <td>-0.512945</td>\n      <td>4.184950</td>\n      <td>38.0</td>\n      <td>7.600000</td>\n      <td>12.0</td>\n      <td>1.0</td>\n      <td>6.024948</td>\n      <td>3274330.0</td>\n      <td>1.516485e+09</td>\n      <td>1.519759e+09</td>\n      <td>-0.400000</td>\n      <td>0.0</td>\n      <td>-1.0</td>\n      <td>0.547723</td>\n      <td>9.400000</td>\n      <td>128</td>\n      <td>65</td>\n      <td>26</td>\n      <td>6</td>\n      <td>6</td>\n      <td>17</td>\n      <td>-69.062500</td>\n      <td>-0.539551</td>\n      <td>6.992188</td>\n      <td>-0.746094</td>\n      <td>0.737305</td>\n      <td>144</td>\n      <td>1.125000</td>\n      <td>12</td>\n      <td>1</td>\n      <td>1.003929</td>\n      <td>9405641.0</td>\n      <td>1.510445e+09</td>\n      <td>1.519850e+09</td>\n      <td>-1.320312</td>\n      <td>0</td>\n      <td>-3</td>\n      <td>1.026680</td>\n      <td>9.773438</td>\n      <td>36.0</td>\n      <td>36.0</td>\n      <td>17.0</td>\n      <td>5.0</td>\n      <td>5.0</td>\n      <td>10.0</td>\n      <td>-19.921875</td>\n      <td>-0.553711</td>\n      <td>0.450928</td>\n      <td>-0.739258</td>\n      <td>0.223877</td>\n      <td>35.0</td>\n      <td>0.972222</td>\n      <td>2.0</td>\n      <td>-1.0</td>\n      <td>0.376913</td>\n      <td>4949682.0</td>\n      <td>1.519992e+09</td>\n      <td>1.524941e+09</td>\n      <td>1.555556</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>0.503953</td>\n      <td>9.833333</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "_uuid": "281b90ed6602a940fac40094a310abbb6ed28b5c"
      },
      "cell_type": "markdown",
      "source": "# Write train and test sets for future use"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "6b5c30df1f3fc70b60de8261c2b13fa58ac0b0e0"
      },
      "cell_type": "code",
      "source": "train_set.to_csv('train_set.csv', index=False)\ntest_set.to_csv('test_set.csv', index=False)\ntarget.to_csv('target.csv', index=False)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "17cc95098cb7021f7c27e06377faa737a691e609"
      },
      "cell_type": "markdown",
      "source": "# Preprocessing"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "1d3acabadd460ac980fc5026588db84eaa0e69cd"
      },
      "cell_type": "code",
      "source": "cat_col = train_set.columns\ncat_col = [col for col in cat_col if col not in np.concatenate((['card_id', 'first_active_month'], numeric_col), axis=0)]\n\nnumeric_col =  [col for col in numeric_col if col not in ['card_id', 'first_active_month']]",
      "execution_count": 7,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "c47482796675c87a0438f4a6a96a801d3482c901"
      },
      "cell_type": "code",
      "source": "def preprocess(trx_data):\n    for cat_col_name in cat_col:\n        lbl = LabelEncoder()\n        lbl.fit(trx_data[cat_col_name].unique().astype('str'))\n        trx_data[cat_col_name] = lbl.transform(trx_data[cat_col_name].astype('str'))\n    \n    for numeric_col_name in numeric_col:\n        trx_data[numeric_col_name] = pd.to_numeric(trx_data[numeric_col_name])\n        min_val = trx_data[numeric_col_name].min()\n        max_val = trx_data[numeric_col_name].max()\n        if min_val == max_val:\n            trx_data[numeric_col_name] = 0\n            print(numeric_col_name)\n        else:\n            trx_data[numeric_col_name] = (max_val - trx_data[numeric_col_name]) / (max_val - min_val)\n\n    return trx_data\n\n# remove nan values from data set\ntrain_set_no_nan = train_set.fillna(-20)\ntest_set_no_nan = test_set.fillna(-20)\n\ntrain_set = preprocess(train_set_no_nan)\ntest_set = preprocess(test_set_no_nan)",
      "execution_count": 8,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "0eaf388d25ace39a6f781d532ead2e802ff78946"
      },
      "cell_type": "markdown",
      "source": "# split the given train set to train and test set"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "b5f97a5ce3daac2ef4caf508bd4692a2d6cd67d6"
      },
      "cell_type": "code",
      "source": "X_train, X_test, y_train, y_test = train_test_split(train_set, target, test_size=0.2, random_state=24)\n\nprint('X_train shape', X_train.shape)\nprint('X_test shape', X_test.shape)",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": "X_train shape (161533, 80)\nX_test shape (40384, 80)\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "be17a6f30efd1d8214606b2ef154b21f6ef3b431"
      },
      "cell_type": "code",
      "source": "X_train.head()",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 10,
          "data": {
            "text/plain": "       first_active_month         ...         new_month_diff_mean\n165743         2017-06-01         ...                    0.293536\n119952         2017-11-01         ...                    0.292512\n89339          2017-09-01         ...                    0.287599\n25589          2014-05-01         ...                    0.311346\n162026         2017-10-01         ...                    0.287599\n\n[5 rows x 80 columns]",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>first_active_month</th>\n      <th>card_id</th>\n      <th>feature_1</th>\n      <th>feature_2</th>\n      <th>feature_3</th>\n      <th>year</th>\n      <th>month</th>\n      <th>elapsed_time</th>\n      <th>history_trx_count</th>\n      <th>history_merchant_id_nunique</th>\n      <th>history_merchant_category_id_nunique</th>\n      <th>history_state_id_nunique</th>\n      <th>history_city_id_nunique</th>\n      <th>history_subsector_id_nunique</th>\n      <th>history_purchase_amount_sum</th>\n      <th>history_purchase_amount_mean</th>\n      <th>history_purchase_amount_max</th>\n      <th>history_purchase_amount_min</th>\n      <th>history_purchase_amount_std</th>\n      <th>history_installments_sum</th>\n      <th>history_installments_mean</th>\n      <th>history_installments_max</th>\n      <th>history_installments_min</th>\n      <th>history_installments_std</th>\n      <th>history_purchase_date_ptp</th>\n      <th>history_purchase_date_min</th>\n      <th>history_purchase_date_max</th>\n      <th>history_month_lag_mean</th>\n      <th>history_month_lag_max</th>\n      <th>history_month_lag_min</th>\n      <th>history_month_lag_std</th>\n      <th>history_month_diff_mean</th>\n      <th>auto_trx_count</th>\n      <th>auto_merchant_id_nunique</th>\n      <th>auto_merchant_category_id_nunique</th>\n      <th>auto_state_id_nunique</th>\n      <th>auto_city_id_nunique</th>\n      <th>auto_subsector_id_nunique</th>\n      <th>auto_purchase_amount_sum</th>\n      <th>auto_purchase_amount_mean</th>\n      <th>auto_purchase_amount_max</th>\n      <th>auto_purchase_amount_min</th>\n      <th>auto_purchase_amount_std</th>\n      <th>auto_installments_sum</th>\n      <th>auto_installments_mean</th>\n      <th>auto_installments_max</th>\n      <th>auto_installments_min</th>\n      <th>auto_installments_std</th>\n      <th>auto_purchase_date_ptp</th>\n      <th>auto_purchase_date_min</th>\n      <th>auto_purchase_date_max</th>\n      <th>auto_month_lag_mean</th>\n      <th>auto_month_lag_max</th>\n      <th>auto_month_lag_min</th>\n      <th>auto_month_lag_std</th>\n      <th>auto_month_diff_mean</th>\n      <th>new_trx_count</th>\n      <th>new_merchant_id_nunique</th>\n      <th>new_merchant_category_id_nunique</th>\n      <th>new_state_id_nunique</th>\n      <th>new_city_id_nunique</th>\n      <th>new_subsector_id_nunique</th>\n      <th>new_purchase_amount_sum</th>\n      <th>new_purchase_amount_mean</th>\n      <th>new_purchase_amount_max</th>\n      <th>new_purchase_amount_min</th>\n      <th>new_purchase_amount_std</th>\n      <th>new_installments_sum</th>\n      <th>new_installments_mean</th>\n      <th>new_installments_max</th>\n      <th>new_installments_min</th>\n      <th>new_installments_std</th>\n      <th>new_purchase_date_ptp</th>\n      <th>new_purchase_date_min</th>\n      <th>new_purchase_date_max</th>\n      <th>new_month_lag_mean</th>\n      <th>new_month_lag_max</th>\n      <th>new_month_lag_min</th>\n      <th>new_month_lag_std</th>\n      <th>new_month_diff_mean</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>165743</th>\n      <td>2017-06-01</td>\n      <td>C_ID_f9f784f2e2</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>6</td>\n      <td>8</td>\n      <td>0.892732</td>\n      <td>0.982353</td>\n      <td>0.733333</td>\n      <td>0.612903</td>\n      <td>0.322581</td>\n      <td>0.432432</td>\n      <td>0.428571</td>\n      <td>0.999832</td>\n      <td>0.999997</td>\n      <td>0.999997</td>\n      <td>0.999997</td>\n      <td>0.999762</td>\n      <td>0.984151</td>\n      <td>0.978691</td>\n      <td>0.977429</td>\n      <td>0.979392</td>\n      <td>0.971186</td>\n      <td>0.756066</td>\n      <td>0.012135</td>\n      <td>0.006264</td>\n      <td>0.257143</td>\n      <td>0.15</td>\n      <td>0.35</td>\n      <td>0.273270</td>\n      <td>0.289116</td>\n      <td>0.908876</td>\n      <td>0.800505</td>\n      <td>0.585106</td>\n      <td>0.947368</td>\n      <td>0.878788</td>\n      <td>0.454545</td>\n      <td>0.693359</td>\n      <td>0.997559</td>\n      <td>0.994141</td>\n      <td>0.999512</td>\n      <td>0.997559</td>\n      <td>0.823068</td>\n      <td>0.964863</td>\n      <td>0.989990</td>\n      <td>1.000000</td>\n      <td>0.995245</td>\n      <td>0.387759</td>\n      <td>0.551730</td>\n      <td>0.000438</td>\n      <td>0.257898</td>\n      <td>0.000000</td>\n      <td>0.583333</td>\n      <td>0.640733</td>\n      <td>0.932981</td>\n      <td>0.751938</td>\n      <td>0.751938</td>\n      <td>0.533333</td>\n      <td>0.382353</td>\n      <td>0.520833</td>\n      <td>0.386364</td>\n      <td>0.651855</td>\n      <td>0.699219</td>\n      <td>0.799805</td>\n      <td>0.699707</td>\n      <td>0.702148</td>\n      <td>0.967773</td>\n      <td>0.614005</td>\n      <td>0.978410</td>\n      <td>0.34375</td>\n      <td>0.901261</td>\n      <td>0.066801</td>\n      <td>0.003361</td>\n      <td>0.000092</td>\n      <td>0.030303</td>\n      <td>0.0</td>\n      <td>0.045455</td>\n      <td>0.010370</td>\n      <td>0.293536</td>\n    </tr>\n    <tr>\n      <th>119952</th>\n      <td>2017-11-01</td>\n      <td>C_ID_c36d60df2c</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>6</td>\n      <td>2</td>\n      <td>0.959720</td>\n      <td>0.986275</td>\n      <td>0.766667</td>\n      <td>0.661290</td>\n      <td>0.322581</td>\n      <td>0.432432</td>\n      <td>0.500000</td>\n      <td>0.999832</td>\n      <td>0.999997</td>\n      <td>0.999997</td>\n      <td>0.999997</td>\n      <td>1.000000</td>\n      <td>0.989599</td>\n      <td>0.979392</td>\n      <td>0.979392</td>\n      <td>0.979392</td>\n      <td>1.000000</td>\n      <td>0.999999</td>\n      <td>0.005455</td>\n      <td>0.005456</td>\n      <td>0.150000</td>\n      <td>0.15</td>\n      <td>0.15</td>\n      <td>1.000000</td>\n      <td>0.285714</td>\n      <td>0.966864</td>\n      <td>0.898990</td>\n      <td>0.744681</td>\n      <td>0.842105</td>\n      <td>0.939394</td>\n      <td>0.575758</td>\n      <td>0.674805</td>\n      <td>0.995605</td>\n      <td>0.992676</td>\n      <td>0.999512</td>\n      <td>0.996094</td>\n      <td>0.942633</td>\n      <td>0.968887</td>\n      <td>0.996997</td>\n      <td>1.000000</td>\n      <td>0.998176</td>\n      <td>0.774618</td>\n      <td>0.110719</td>\n      <td>0.006458</td>\n      <td>0.103455</td>\n      <td>0.000000</td>\n      <td>0.166667</td>\n      <td>0.864439</td>\n      <td>0.937388</td>\n      <td>0.620155</td>\n      <td>0.620155</td>\n      <td>0.316667</td>\n      <td>0.264706</td>\n      <td>0.479167</td>\n      <td>0.250000</td>\n      <td>0.645996</td>\n      <td>0.692383</td>\n      <td>0.738281</td>\n      <td>0.699707</td>\n      <td>0.684082</td>\n      <td>0.939453</td>\n      <td>0.607323</td>\n      <td>0.970559</td>\n      <td>0.34375</td>\n      <td>0.894379</td>\n      <td>0.040831</td>\n      <td>0.003376</td>\n      <td>0.000016</td>\n      <td>0.029781</td>\n      <td>0.0</td>\n      <td>0.045455</td>\n      <td>0.010788</td>\n      <td>0.292512</td>\n    </tr>\n    <tr>\n      <th>89339</th>\n      <td>2017-09-01</td>\n      <td>C_ID_42699e8b0c</td>\n      <td>3</td>\n      <td>0</td>\n      <td>0</td>\n      <td>6</td>\n      <td>11</td>\n      <td>0.933012</td>\n      <td>0.984967</td>\n      <td>0.755556</td>\n      <td>0.629032</td>\n      <td>0.322581</td>\n      <td>0.432432</td>\n      <td>0.452381</td>\n      <td>0.999832</td>\n      <td>0.999997</td>\n      <td>0.999997</td>\n      <td>0.999997</td>\n      <td>0.999761</td>\n      <td>0.983160</td>\n      <td>0.975793</td>\n      <td>0.968597</td>\n      <td>0.979392</td>\n      <td>0.963759</td>\n      <td>0.854852</td>\n      <td>0.008744</td>\n      <td>0.005251</td>\n      <td>0.200000</td>\n      <td>0.15</td>\n      <td>0.25</td>\n      <td>0.280634</td>\n      <td>0.301587</td>\n      <td>0.987771</td>\n      <td>0.989899</td>\n      <td>0.946809</td>\n      <td>0.947368</td>\n      <td>0.984848</td>\n      <td>0.878788</td>\n      <td>0.668945</td>\n      <td>0.995117</td>\n      <td>0.978516</td>\n      <td>1.000000</td>\n      <td>0.987305</td>\n      <td>0.964976</td>\n      <td>0.959973</td>\n      <td>0.987988</td>\n      <td>0.846154</td>\n      <td>0.990660</td>\n      <td>0.617788</td>\n      <td>0.285263</td>\n      <td>0.000077</td>\n      <td>0.206358</td>\n      <td>0.000000</td>\n      <td>0.333333</td>\n      <td>0.741084</td>\n      <td>0.951049</td>\n      <td>0.829457</td>\n      <td>0.829457</td>\n      <td>0.633333</td>\n      <td>0.352941</td>\n      <td>0.541667</td>\n      <td>0.500000</td>\n      <td>0.589355</td>\n      <td>0.665039</td>\n      <td>0.770996</td>\n      <td>0.674316</td>\n      <td>0.689941</td>\n      <td>0.969727</td>\n      <td>0.533144</td>\n      <td>0.968597</td>\n      <td>0.40625</td>\n      <td>0.857929</td>\n      <td>0.771857</td>\n      <td>0.002342</td>\n      <td>0.001544</td>\n      <td>0.022727</td>\n      <td>0.0</td>\n      <td>0.045455</td>\n      <td>0.000000</td>\n      <td>0.287599</td>\n    </tr>\n    <tr>\n      <th>25589</th>\n      <td>2014-05-01</td>\n      <td>C_ID_750614dd76</td>\n      <td>2</td>\n      <td>2</td>\n      <td>1</td>\n      <td>3</td>\n      <td>7</td>\n      <td>0.399299</td>\n      <td>0.985621</td>\n      <td>0.755556</td>\n      <td>0.645161</td>\n      <td>0.290323</td>\n      <td>0.405405</td>\n      <td>0.476190</td>\n      <td>0.999832</td>\n      <td>0.999997</td>\n      <td>0.999997</td>\n      <td>0.999997</td>\n      <td>0.999764</td>\n      <td>0.990094</td>\n      <td>0.980373</td>\n      <td>0.980373</td>\n      <td>0.980373</td>\n      <td>0.972494</td>\n      <td>0.437682</td>\n      <td>0.020489</td>\n      <td>0.006954</td>\n      <td>0.375000</td>\n      <td>0.20</td>\n      <td>0.55</td>\n      <td>0.145334</td>\n      <td>0.297619</td>\n      <td>0.992110</td>\n      <td>0.959596</td>\n      <td>0.882979</td>\n      <td>0.947368</td>\n      <td>0.954545</td>\n      <td>0.696970</td>\n      <td>0.667969</td>\n      <td>0.998535</td>\n      <td>0.997559</td>\n      <td>1.000000</td>\n      <td>0.997070</td>\n      <td>0.994565</td>\n      <td>0.987272</td>\n      <td>1.000000</td>\n      <td>0.923077</td>\n      <td>1.000000</td>\n      <td>0.218255</td>\n      <td>0.825823</td>\n      <td>0.072956</td>\n      <td>0.404251</td>\n      <td>0.090909</td>\n      <td>0.833333</td>\n      <td>0.545224</td>\n      <td>0.940559</td>\n      <td>0.837209</td>\n      <td>0.837209</td>\n      <td>0.650000</td>\n      <td>0.382353</td>\n      <td>0.562500</td>\n      <td>0.522727</td>\n      <td>0.610352</td>\n      <td>0.699707</td>\n      <td>0.800781</td>\n      <td>0.699707</td>\n      <td>1.000000</td>\n      <td>0.980469</td>\n      <td>0.633838</td>\n      <td>0.980373</td>\n      <td>0.37500</td>\n      <td>1.000000</td>\n      <td>0.999996</td>\n      <td>0.000013</td>\n      <td>0.000014</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>0.311346</td>\n    </tr>\n    <tr>\n      <th>162026</th>\n      <td>2017-10-01</td>\n      <td>C_ID_18d2ec30fc</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>6</td>\n      <td>1</td>\n      <td>0.946147</td>\n      <td>0.984314</td>\n      <td>0.744444</td>\n      <td>0.629032</td>\n      <td>0.322581</td>\n      <td>0.432432</td>\n      <td>0.452381</td>\n      <td>0.999828</td>\n      <td>0.999996</td>\n      <td>0.999995</td>\n      <td>0.999997</td>\n      <td>0.999673</td>\n      <td>0.983160</td>\n      <td>0.976938</td>\n      <td>0.974485</td>\n      <td>0.979392</td>\n      <td>0.968524</td>\n      <td>0.748491</td>\n      <td>0.006309</td>\n      <td>0.000256</td>\n      <td>0.062500</td>\n      <td>0.00</td>\n      <td>0.15</td>\n      <td>0.271786</td>\n      <td>0.285714</td>\n      <td>0.964497</td>\n      <td>0.888889</td>\n      <td>0.755319</td>\n      <td>0.842105</td>\n      <td>0.924242</td>\n      <td>0.575758</td>\n      <td>0.660156</td>\n      <td>0.971680</td>\n      <td>0.927734</td>\n      <td>0.999512</td>\n      <td>0.953613</td>\n      <td>0.894928</td>\n      <td>0.954299</td>\n      <td>0.989990</td>\n      <td>1.000000</td>\n      <td>0.990902</td>\n      <td>0.691486</td>\n      <td>0.231007</td>\n      <td>0.028882</td>\n      <td>0.143375</td>\n      <td>0.000000</td>\n      <td>0.250000</td>\n      <td>0.811096</td>\n      <td>0.933946</td>\n      <td>0.736434</td>\n      <td>0.736434</td>\n      <td>0.466667</td>\n      <td>0.323529</td>\n      <td>0.458333</td>\n      <td>0.272727</td>\n      <td>0.617676</td>\n      <td>0.690918</td>\n      <td>0.770020</td>\n      <td>0.700195</td>\n      <td>0.687988</td>\n      <td>0.951172</td>\n      <td>0.594607</td>\n      <td>0.968597</td>\n      <td>0.40625</td>\n      <td>0.885822</td>\n      <td>0.191935</td>\n      <td>0.003150</td>\n      <td>0.000319</td>\n      <td>0.022727</td>\n      <td>0.0</td>\n      <td>0.045455</td>\n      <td>0.009090</td>\n      <td>0.287599</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "d030c05a5d135ef44fb12e0f1163d8eedd895ec2"
      },
      "cell_type": "code",
      "source": "X_test.head()",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 11,
          "data": {
            "text/plain": "       first_active_month         ...         new_month_diff_mean\n110727         2017-12-01         ...                    1.000000\n108935         2017-02-01         ...                    0.287599\n22893          2017-09-01         ...                    0.287599\n79140          2016-04-01         ...                    0.291557\n12651          2017-06-01         ...                    0.168865\n\n[5 rows x 80 columns]",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>first_active_month</th>\n      <th>card_id</th>\n      <th>feature_1</th>\n      <th>feature_2</th>\n      <th>feature_3</th>\n      <th>year</th>\n      <th>month</th>\n      <th>elapsed_time</th>\n      <th>history_trx_count</th>\n      <th>history_merchant_id_nunique</th>\n      <th>history_merchant_category_id_nunique</th>\n      <th>history_state_id_nunique</th>\n      <th>history_city_id_nunique</th>\n      <th>history_subsector_id_nunique</th>\n      <th>history_purchase_amount_sum</th>\n      <th>history_purchase_amount_mean</th>\n      <th>history_purchase_amount_max</th>\n      <th>history_purchase_amount_min</th>\n      <th>history_purchase_amount_std</th>\n      <th>history_installments_sum</th>\n      <th>history_installments_mean</th>\n      <th>history_installments_max</th>\n      <th>history_installments_min</th>\n      <th>history_installments_std</th>\n      <th>history_purchase_date_ptp</th>\n      <th>history_purchase_date_min</th>\n      <th>history_purchase_date_max</th>\n      <th>history_month_lag_mean</th>\n      <th>history_month_lag_max</th>\n      <th>history_month_lag_min</th>\n      <th>history_month_lag_std</th>\n      <th>history_month_diff_mean</th>\n      <th>auto_trx_count</th>\n      <th>auto_merchant_id_nunique</th>\n      <th>auto_merchant_category_id_nunique</th>\n      <th>auto_state_id_nunique</th>\n      <th>auto_city_id_nunique</th>\n      <th>auto_subsector_id_nunique</th>\n      <th>auto_purchase_amount_sum</th>\n      <th>auto_purchase_amount_mean</th>\n      <th>auto_purchase_amount_max</th>\n      <th>auto_purchase_amount_min</th>\n      <th>auto_purchase_amount_std</th>\n      <th>auto_installments_sum</th>\n      <th>auto_installments_mean</th>\n      <th>auto_installments_max</th>\n      <th>auto_installments_min</th>\n      <th>auto_installments_std</th>\n      <th>auto_purchase_date_ptp</th>\n      <th>auto_purchase_date_min</th>\n      <th>auto_purchase_date_max</th>\n      <th>auto_month_lag_mean</th>\n      <th>auto_month_lag_max</th>\n      <th>auto_month_lag_min</th>\n      <th>auto_month_lag_std</th>\n      <th>auto_month_diff_mean</th>\n      <th>new_trx_count</th>\n      <th>new_merchant_id_nunique</th>\n      <th>new_merchant_category_id_nunique</th>\n      <th>new_state_id_nunique</th>\n      <th>new_city_id_nunique</th>\n      <th>new_subsector_id_nunique</th>\n      <th>new_purchase_amount_sum</th>\n      <th>new_purchase_amount_mean</th>\n      <th>new_purchase_amount_max</th>\n      <th>new_purchase_amount_min</th>\n      <th>new_purchase_amount_std</th>\n      <th>new_installments_sum</th>\n      <th>new_installments_mean</th>\n      <th>new_installments_max</th>\n      <th>new_installments_min</th>\n      <th>new_installments_std</th>\n      <th>new_purchase_date_ptp</th>\n      <th>new_purchase_date_min</th>\n      <th>new_purchase_date_max</th>\n      <th>new_month_lag_mean</th>\n      <th>new_month_lag_max</th>\n      <th>new_month_lag_min</th>\n      <th>new_month_lag_std</th>\n      <th>new_month_diff_mean</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>110727</th>\n      <td>2017-12-01</td>\n      <td>C_ID_3d38c16da9</td>\n      <td>2</td>\n      <td>2</td>\n      <td>1</td>\n      <td>6</td>\n      <td>3</td>\n      <td>0.972855</td>\n      <td>0.986275</td>\n      <td>0.766667</td>\n      <td>0.661290</td>\n      <td>0.322581</td>\n      <td>0.432432</td>\n      <td>0.500000</td>\n      <td>0.999832</td>\n      <td>0.999997</td>\n      <td>0.999997</td>\n      <td>0.999997</td>\n      <td>1.000000</td>\n      <td>0.988608</td>\n      <td>0.977429</td>\n      <td>0.977429</td>\n      <td>0.977429</td>\n      <td>1.000000</td>\n      <td>0.999999</td>\n      <td>0.001434</td>\n      <td>0.001435</td>\n      <td>0.000000</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>1.000000</td>\n      <td>0.285714</td>\n      <td>0.997239</td>\n      <td>0.982323</td>\n      <td>0.946809</td>\n      <td>0.894737</td>\n      <td>0.954545</td>\n      <td>0.878788</td>\n      <td>0.666504</td>\n      <td>0.996582</td>\n      <td>0.998535</td>\n      <td>1.000000</td>\n      <td>0.999023</td>\n      <td>0.987923</td>\n      <td>0.964801</td>\n      <td>0.996997</td>\n      <td>1.000000</td>\n      <td>0.992975</td>\n      <td>0.914627</td>\n      <td>0.010962</td>\n      <td>0.064263</td>\n      <td>0.069602</td>\n      <td>0.0</td>\n      <td>0.083333</td>\n      <td>0.882842</td>\n      <td>0.948718</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>0.717285</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.00000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>108935</th>\n      <td>2017-02-01</td>\n      <td>C_ID_baa868fe6e</td>\n      <td>2</td>\n      <td>2</td>\n      <td>1</td>\n      <td>6</td>\n      <td>4</td>\n      <td>0.840193</td>\n      <td>0.973203</td>\n      <td>0.688889</td>\n      <td>0.580645</td>\n      <td>0.258065</td>\n      <td>0.351351</td>\n      <td>0.404762</td>\n      <td>0.999834</td>\n      <td>0.999997</td>\n      <td>0.999997</td>\n      <td>0.999997</td>\n      <td>0.999764</td>\n      <td>0.975731</td>\n      <td>0.979018</td>\n      <td>0.976447</td>\n      <td>0.979392</td>\n      <td>0.971228</td>\n      <td>0.265861</td>\n      <td>0.018375</td>\n      <td>0.000705</td>\n      <td>0.152381</td>\n      <td>0.00</td>\n      <td>0.50</td>\n      <td>0.239468</td>\n      <td>0.286848</td>\n      <td>0.953057</td>\n      <td>0.878788</td>\n      <td>0.765957</td>\n      <td>0.842105</td>\n      <td>0.939394</td>\n      <td>0.666667</td>\n      <td>0.680664</td>\n      <td>0.998535</td>\n      <td>0.990723</td>\n      <td>1.000000</td>\n      <td>0.997070</td>\n      <td>0.892512</td>\n      <td>0.961594</td>\n      <td>0.991992</td>\n      <td>1.000000</td>\n      <td>0.995027</td>\n      <td>0.160892</td>\n      <td>0.845104</td>\n      <td>0.029205</td>\n      <td>0.406884</td>\n      <td>0.0</td>\n      <td>0.916667</td>\n      <td>0.596967</td>\n      <td>0.926891</td>\n      <td>0.790698</td>\n      <td>0.790698</td>\n      <td>0.566667</td>\n      <td>0.382353</td>\n      <td>0.562500</td>\n      <td>0.431818</td>\n      <td>0.631836</td>\n      <td>0.698730</td>\n      <td>0.798340</td>\n      <td>0.699707</td>\n      <td>0.701660</td>\n      <td>0.973633</td>\n      <td>0.615530</td>\n      <td>0.977429</td>\n      <td>0.40625</td>\n      <td>0.897046</td>\n      <td>0.258780</td>\n      <td>0.003080</td>\n      <td>0.000483</td>\n      <td>0.012987</td>\n      <td>0.000000</td>\n      <td>0.045455</td>\n      <td>0.010584</td>\n      <td>0.287599</td>\n    </tr>\n    <tr>\n      <th>22893</th>\n      <td>2017-09-01</td>\n      <td>C_ID_2ce1c19fa6</td>\n      <td>2</td>\n      <td>0</td>\n      <td>1</td>\n      <td>6</td>\n      <td>11</td>\n      <td>0.933012</td>\n      <td>0.983660</td>\n      <td>0.755556</td>\n      <td>0.645161</td>\n      <td>0.290323</td>\n      <td>0.405405</td>\n      <td>0.476190</td>\n      <td>0.999832</td>\n      <td>0.999997</td>\n      <td>0.999997</td>\n      <td>0.999997</td>\n      <td>0.999765</td>\n      <td>0.988113</td>\n      <td>0.979588</td>\n      <td>0.979392</td>\n      <td>0.980373</td>\n      <td>0.971879</td>\n      <td>0.761053</td>\n      <td>0.008998</td>\n      <td>0.003247</td>\n      <td>0.090000</td>\n      <td>0.05</td>\n      <td>0.25</td>\n      <td>0.253612</td>\n      <td>0.285714</td>\n      <td>0.976726</td>\n      <td>0.909091</td>\n      <td>0.776596</td>\n      <td>1.000000</td>\n      <td>0.969697</td>\n      <td>0.636364</td>\n      <td>0.673340</td>\n      <td>0.998535</td>\n      <td>0.998535</td>\n      <td>0.999512</td>\n      <td>0.999512</td>\n      <td>0.994565</td>\n      <td>0.987272</td>\n      <td>1.000000</td>\n      <td>0.923077</td>\n      <td>1.000000</td>\n      <td>0.641601</td>\n      <td>0.312906</td>\n      <td>0.051371</td>\n      <td>0.186814</td>\n      <td>0.0</td>\n      <td>0.333333</td>\n      <td>0.778807</td>\n      <td>0.939470</td>\n      <td>0.821705</td>\n      <td>0.821705</td>\n      <td>0.616667</td>\n      <td>0.382353</td>\n      <td>0.541667</td>\n      <td>0.477273</td>\n      <td>0.618164</td>\n      <td>0.699219</td>\n      <td>0.800293</td>\n      <td>0.699707</td>\n      <td>0.702637</td>\n      <td>0.980469</td>\n      <td>0.633838</td>\n      <td>0.980373</td>\n      <td>0.37500</td>\n      <td>0.902665</td>\n      <td>0.935895</td>\n      <td>0.002672</td>\n      <td>0.002448</td>\n      <td>0.045455</td>\n      <td>0.045455</td>\n      <td>0.045455</td>\n      <td>0.034148</td>\n      <td>0.287599</td>\n    </tr>\n    <tr>\n      <th>79140</th>\n      <td>2016-04-01</td>\n      <td>C_ID_03a8c5345e</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>5</td>\n      <td>6</td>\n      <td>0.706217</td>\n      <td>0.982353</td>\n      <td>0.733333</td>\n      <td>0.629032</td>\n      <td>0.322581</td>\n      <td>0.405405</td>\n      <td>0.452381</td>\n      <td>0.999832</td>\n      <td>0.999997</td>\n      <td>0.999997</td>\n      <td>0.999997</td>\n      <td>0.999764</td>\n      <td>0.989599</td>\n      <td>0.980233</td>\n      <td>0.979392</td>\n      <td>0.980373</td>\n      <td>0.971974</td>\n      <td>0.238509</td>\n      <td>0.018741</td>\n      <td>0.000413</td>\n      <td>0.107143</td>\n      <td>0.00</td>\n      <td>0.50</td>\n      <td>0.193894</td>\n      <td>0.285714</td>\n      <td>0.957396</td>\n      <td>0.858586</td>\n      <td>0.648936</td>\n      <td>0.842105</td>\n      <td>0.909091</td>\n      <td>0.545455</td>\n      <td>0.676758</td>\n      <td>0.995117</td>\n      <td>0.992188</td>\n      <td>0.999512</td>\n      <td>0.994629</td>\n      <td>0.994565</td>\n      <td>0.987272</td>\n      <td>1.000000</td>\n      <td>0.923077</td>\n      <td>1.000000</td>\n      <td>0.027925</td>\n      <td>0.987400</td>\n      <td>0.018507</td>\n      <td>0.571495</td>\n      <td>0.0</td>\n      <td>1.000000</td>\n      <td>0.387071</td>\n      <td>0.927273</td>\n      <td>0.798450</td>\n      <td>0.806202</td>\n      <td>0.566667</td>\n      <td>0.382353</td>\n      <td>0.541667</td>\n      <td>0.454545</td>\n      <td>0.627441</td>\n      <td>0.698242</td>\n      <td>0.798828</td>\n      <td>0.699219</td>\n      <td>0.701660</td>\n      <td>0.980469</td>\n      <td>0.633838</td>\n      <td>0.980373</td>\n      <td>0.37500</td>\n      <td>0.902665</td>\n      <td>0.527713</td>\n      <td>0.002589</td>\n      <td>0.000934</td>\n      <td>0.022727</td>\n      <td>0.000000</td>\n      <td>0.045455</td>\n      <td>0.007697</td>\n      <td>0.291557</td>\n    </tr>\n    <tr>\n      <th>12651</th>\n      <td>2017-06-01</td>\n      <td>C_ID_a51a3996c2</td>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>6</td>\n      <td>8</td>\n      <td>0.892732</td>\n      <td>0.984314</td>\n      <td>0.755556</td>\n      <td>0.645161</td>\n      <td>0.322581</td>\n      <td>0.405405</td>\n      <td>0.476190</td>\n      <td>0.999832</td>\n      <td>0.999997</td>\n      <td>0.999997</td>\n      <td>0.999997</td>\n      <td>0.999765</td>\n      <td>0.990094</td>\n      <td>0.980373</td>\n      <td>0.980373</td>\n      <td>0.980373</td>\n      <td>0.972494</td>\n      <td>0.915257</td>\n      <td>0.014731</td>\n      <td>0.012692</td>\n      <td>0.137500</td>\n      <td>0.10</td>\n      <td>0.15</td>\n      <td>0.297762</td>\n      <td>0.166667</td>\n      <td>0.975148</td>\n      <td>0.914141</td>\n      <td>0.776596</td>\n      <td>1.000000</td>\n      <td>0.939394</td>\n      <td>0.606061</td>\n      <td>0.673340</td>\n      <td>0.998535</td>\n      <td>0.998047</td>\n      <td>0.999512</td>\n      <td>0.999023</td>\n      <td>0.994565</td>\n      <td>0.987272</td>\n      <td>1.000000</td>\n      <td>0.923077</td>\n      <td>1.000000</td>\n      <td>0.767201</td>\n      <td>0.565307</td>\n      <td>0.420992</td>\n      <td>0.093154</td>\n      <td>0.0</td>\n      <td>0.166667</td>\n      <td>0.861649</td>\n      <td>0.546746</td>\n      <td>0.790698</td>\n      <td>0.790698</td>\n      <td>0.583333</td>\n      <td>0.382353</td>\n      <td>0.541667</td>\n      <td>0.454545</td>\n      <td>0.632812</td>\n      <td>0.699219</td>\n      <td>0.798828</td>\n      <td>0.700195</td>\n      <td>0.701660</td>\n      <td>0.980469</td>\n      <td>0.633838</td>\n      <td>0.980373</td>\n      <td>0.37500</td>\n      <td>0.902665</td>\n      <td>0.566937</td>\n      <td>0.011330</td>\n      <td>0.009813</td>\n      <td>0.019481</td>\n      <td>0.000000</td>\n      <td>0.045455</td>\n      <td>0.008335</td>\n      <td>0.168865</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "_uuid": "565f7c63304115cdc8a6aaa3c5cddadd0b3c5ed2"
      },
      "cell_type": "markdown",
      "source": "# Classic ML model to form a benchmark"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "38e8bd0683b71e7af9264785787f34782e79ff8a"
      },
      "cell_type": "code",
      "source": "lgb_model = lgb.LGBMRegressor()\nlgb_model.fit(X_train[used_col], y_train.values)\n\nlgb_pred_test = lgb_model.predict(X_test[used_col])\nlgb_pred_train = lgb_model.predict(X_train[used_col])\n\nprint('test RMSE:', mean_squared_error(y_test, lgb_pred_test) ** 0.5)\nprint('train RMSE:', mean_squared_error(y_train, lgb_pred_train) ** 0.5)",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": "test RMSE: 3.5927786175842464\ntrain RMSE: 3.4121657257070446\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "_uuid": "7cefaf989f7496b60442ec4b32b278edc3b14410"
      },
      "cell_type": "markdown",
      "source": "# Create embedding to categorical feature"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "43185616539bf08f3eebd2c80a306940f23088b7"
      },
      "cell_type": "code",
      "source": "f1_unique_val = len(train_set['feature_1'].unique())\nf2_unique_val = len(train_set['feature_2'].unique())\nf3_unique_val = len(train_set['feature_3'].unique())\nyear_unique_val = len(train_set['year'].unique())\nmonth_unique_val = len(train_set['month'].unique())",
      "execution_count": 13,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "71ee8991faa513ee2ebe54ff0335848cd73be0a0"
      },
      "cell_type": "code",
      "source": "f1_inp = Input(shape=(1,),dtype='int64')\nf2_inp = Input(shape=(1,),dtype='int64')\nf3_inp = Input(shape=(1,),dtype='int64')\nyear_inp = Input(shape=(1,),dtype='int64')\nmonth_inp = Input(shape=(1,),dtype='int64')\n\nf1_emb = Embedding(f1_unique_val,2,input_length=1, embeddings_regularizer=l2(1e-6))(f1_inp)\nf2_emb = Embedding(f2_unique_val,1,input_length=1, embeddings_regularizer=l2(1e-6))(f2_inp)\nf3_emb = Embedding(f3_unique_val,1,input_length=1, embeddings_regularizer=l2(1e-6))(f3_inp)\nyear_emb = Embedding(year_unique_val,3,input_length=1, embeddings_regularizer=l2(1e-6))(year_inp)\nmonth_emb = Embedding(month_unique_val,4,input_length=1, embeddings_regularizer=l2(1e-6))(month_inp)",
      "execution_count": 14,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "b11848ae55fe9b65848541054fa47d90c913b8a6"
      },
      "cell_type": "markdown",
      "source": "# Predicting the target using only the categorical features embeddings"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "fa07722e76be13e0f6cd975da0d900b2d01d5c12"
      },
      "cell_type": "code",
      "source": "x = concatenate([f1_emb,f2_emb,f3_emb,year_emb,month_emb])\nx = Flatten()(x)\nx = BatchNormalization()(x)\nx = Dense(10,activation='relu')(x)\nx = Dense(10,activation='relu')(x)\nx = Dropout(0.4)(x)\nx = BatchNormalization()(x)\nx = Dense(10,activation='relu')(x)\nx = Dense(10,activation='relu')(x)\nx = Dropout(0.7)(x)\nx = Dense(1, activation='sigmoid')(x) #activation='linear'\nemb_model = Model([f1_inp,f2_inp,f3_inp,year_inp,month_inp],x)\n#emb_model.compile(loss='mse',optimizer='adam')\n\nemb_model.compile(optimizer=\"RMSProp\", loss=root_mean_squared_error)\n\nprint(emb_model.summary())\n\nemb_model.fit([X_train[col] for col in cat_col], y_train, epochs=5)\n\nemb_pred_test = emb_model.predict([X_test[col] for col in cat_col])\nemb_pred_train = emb_model.predict([X_train[col] for col in cat_col])\n\nprint('test RMSE', mean_squared_error(y_test, emb_pred_test) ** 0.5)\nprint('train RMSE', mean_squared_error(y_train, emb_pred_train) ** 0.5)",
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": "__________________________________________________________________________________________________\nLayer (type)                    Output Shape         Param #     Connected to                     \n==================================================================================================\ninput_1 (InputLayer)            (None, 1)            0                                            \n__________________________________________________________________________________________________\ninput_2 (InputLayer)            (None, 1)            0                                            \n__________________________________________________________________________________________________\ninput_3 (InputLayer)            (None, 1)            0                                            \n__________________________________________________________________________________________________\ninput_4 (InputLayer)            (None, 1)            0                                            \n__________________________________________________________________________________________________\ninput_5 (InputLayer)            (None, 1)            0                                            \n__________________________________________________________________________________________________\nembedding_1 (Embedding)         (None, 1, 2)         10          input_1[0][0]                    \n__________________________________________________________________________________________________\nembedding_2 (Embedding)         (None, 1, 1)         3           input_2[0][0]                    \n__________________________________________________________________________________________________\nembedding_3 (Embedding)         (None, 1, 1)         2           input_3[0][0]                    \n__________________________________________________________________________________________________\nembedding_4 (Embedding)         (None, 1, 3)         24          input_4[0][0]                    \n__________________________________________________________________________________________________\nembedding_5 (Embedding)         (None, 1, 4)         48          input_5[0][0]                    \n__________________________________________________________________________________________________\nconcatenate_1 (Concatenate)     (None, 1, 11)        0           embedding_1[0][0]                \n                                                                 embedding_2[0][0]                \n                                                                 embedding_3[0][0]                \n                                                                 embedding_4[0][0]                \n                                                                 embedding_5[0][0]                \n__________________________________________________________________________________________________\nflatten_1 (Flatten)             (None, 11)           0           concatenate_1[0][0]              \n__________________________________________________________________________________________________\nbatch_normalization_1 (BatchNor (None, 11)           44          flatten_1[0][0]                  \n__________________________________________________________________________________________________\ndense_1 (Dense)                 (None, 10)           120         batch_normalization_1[0][0]      \n__________________________________________________________________________________________________\ndense_2 (Dense)                 (None, 10)           110         dense_1[0][0]                    \n__________________________________________________________________________________________________\ndropout_1 (Dropout)             (None, 10)           0           dense_2[0][0]                    \n__________________________________________________________________________________________________\nbatch_normalization_2 (BatchNor (None, 10)           40          dropout_1[0][0]                  \n__________________________________________________________________________________________________\ndense_3 (Dense)                 (None, 10)           110         batch_normalization_2[0][0]      \n__________________________________________________________________________________________________\ndense_4 (Dense)                 (None, 10)           110         dense_3[0][0]                    \n__________________________________________________________________________________________________\ndropout_2 (Dropout)             (None, 10)           0           dense_4[0][0]                    \n__________________________________________________________________________________________________\ndense_5 (Dense)                 (None, 1)            11          dropout_2[0][0]                  \n==================================================================================================\nTotal params: 632\nTrainable params: 590\nNon-trainable params: 42\n__________________________________________________________________________________________________\nNone\nEpoch 1/5\n161533/161533 [==============================] - 50s 309us/step - loss: 3.1493\nEpoch 2/5\n161533/161533 [==============================] - 47s 290us/step - loss: 3.1263\nEpoch 3/5\n161533/161533 [==============================] - 47s 288us/step - loss: 3.1324\nEpoch 4/5\n161533/161533 [==============================] - 47s 288us/step - loss: 3.1303\nEpoch 5/5\n161533/161533 [==============================] - 47s 288us/step - loss: 3.1435\ntest RMSE 3.7813943585010583\ntrain RMSE 3.8925313419782923\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "_uuid": "8991d93bb0e46777090170c7b8e3669d7a2cc490"
      },
      "cell_type": "markdown",
      "source": "# Use the embeddings we got as a feature extractor for a LGBMRegressor model"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "181de76369ffd9f6e102904f355c0a59cfdb9b38"
      },
      "cell_type": "code",
      "source": "emb_output = emb_model.layers[11].output\n\nfeature_model = Model(emb_model.input, emb_output)\n\nfeature_model.compile(optimizer = \"RMSProp\", loss = root_mean_squared_error)\nprint(feature_model.summary())\n\nfeaturs = feature_model.predict([X_train[col] for col in cat_col])\nfeatures_test = feature_model.predict([X_test[col] for col in cat_col])\n\nlgb_model = lgb.LGBMRegressor()\nlgb_model.fit(featurs, y_train.values)\n\nlgb_pred_test = lgb_model.predict(features_test)\nlgb_pred_train = lgb_model.predict(featurs)\n\nprint('test RMSE', mean_squared_error(y_test, lgb_pred_test) ** 0.5)\nprint('train RMSE', mean_squared_error(y_train, lgb_pred_train) ** 0.5)",
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": "__________________________________________________________________________________________________\nLayer (type)                    Output Shape         Param #     Connected to                     \n==================================================================================================\ninput_1 (InputLayer)            (None, 1)            0                                            \n__________________________________________________________________________________________________\ninput_2 (InputLayer)            (None, 1)            0                                            \n__________________________________________________________________________________________________\ninput_3 (InputLayer)            (None, 1)            0                                            \n__________________________________________________________________________________________________\ninput_4 (InputLayer)            (None, 1)            0                                            \n__________________________________________________________________________________________________\ninput_5 (InputLayer)            (None, 1)            0                                            \n__________________________________________________________________________________________________\nembedding_1 (Embedding)         (None, 1, 2)         10          input_1[0][0]                    \n__________________________________________________________________________________________________\nembedding_2 (Embedding)         (None, 1, 1)         3           input_2[0][0]                    \n__________________________________________________________________________________________________\nembedding_3 (Embedding)         (None, 1, 1)         2           input_3[0][0]                    \n__________________________________________________________________________________________________\nembedding_4 (Embedding)         (None, 1, 3)         24          input_4[0][0]                    \n__________________________________________________________________________________________________\nembedding_5 (Embedding)         (None, 1, 4)         48          input_5[0][0]                    \n__________________________________________________________________________________________________\nconcatenate_1 (Concatenate)     (None, 1, 11)        0           embedding_1[0][0]                \n                                                                 embedding_2[0][0]                \n                                                                 embedding_3[0][0]                \n                                                                 embedding_4[0][0]                \n                                                                 embedding_5[0][0]                \n__________________________________________________________________________________________________\nflatten_1 (Flatten)             (None, 11)           0           concatenate_1[0][0]              \n==================================================================================================\nTotal params: 87\nTrainable params: 87\nNon-trainable params: 0\n__________________________________________________________________________________________________\nNone\ntest RMSE 3.7566186401610593\ntrain RMSE 3.8566066458145998\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "_uuid": "1f9502dc4a042bb0c1e4eb1026ab1ba72fa582e1"
      },
      "cell_type": "markdown",
      "source": "# Add the rest of the features "
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "093c9733924a4ec78a336587be18fa3791dcac6b"
      },
      "cell_type": "code",
      "source": "# define continuous input\ncontinuous_input = Input(shape=(len(numeric_col),)) #train_set_no_nan[numeric_col].shape[1]\n\n# define categorical input                         \nf1_emb = Reshape((2,))(f1_emb)\nf2_emb = Reshape((1,))(f2_emb)\nf3_emb = Reshape((1,))(f3_emb)\nyear_emb = Reshape((3,))(year_emb)\nmonth_emb = Reshape((4,))(month_emb)\n                         \n#split train set to train and validation set\nX_train_val, X_val, y_train_val, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=6)\n                         \n# define function to create input to model\ndef get_input(data):\n    inp = [data[numeric_col], data['feature_1'], data['feature_2'], data['feature_3'],\n      data['year'], data['month']]\n    return inp",
      "execution_count": 17,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "91e12c16b437a35c5cc063095121613e18ce343a"
      },
      "cell_type": "code",
      "source": "x = concatenate([continuous_input,f1_emb,f2_emb,f3_emb,year_emb,month_emb])\nx = BatchNormalization()(x)\nx = Dense(10,activation='relu')(x)\nx = Dense(10,activation='relu')(x)\nx = Dropout(0.4)(x)\nx = BatchNormalization()(x)\nx = Dense(10,activation='relu')(x)\nx = Dense(10,activation='relu')(x)\nx = Dropout(0.7)(x)\nx = Dense(1, activation='linear')(x)\nemb_cont_model = Model([continuous_input,f1_inp,f2_inp,f3_inp,year_inp,month_inp],x)\n\nrmsprop_opt = RMSprop(lr=0.005)\nemb_cont_model.compile(optimizer = rmsprop_opt, loss = root_mean_squared_error)\n\nprint(emb_cont_model.summary())\n\ndef set_callbacks(description='run1',patience=15,tb_base_logdir='./logs/'):\n    cp = ModelCheckpoint('best_model_weights_{}.h5'.format(description),save_best_only=True)\n    es = EarlyStopping(patience=patience,monitor='val_loss')\n    rlop = ReduceLROnPlateau(patience=5)   \n    tb = TensorBoard(log_dir='{}{}'.format(tb_base_logdir,description))\n    cb = [cp,es,tb,rlop]\n    return cb\n\nhistory = emb_cont_model.fit(get_input(X_train_val), y_train_val, epochs=5, batch_size=16, \n          validation_data=(get_input(X_val), y_val),callbacks=set_callbacks())\n\nemb_cont_pred_test = emb_cont_model.predict(get_input(X_test))\nemb_cont_pred_train = emb_cont_model.predict(get_input(X_train_val))\n\nprint('test RMSE', mean_squared_error(y_test, emb_cont_pred_test) ** 0.5)\nprint('train RMSE', mean_squared_error(y_train_val, emb_cont_pred_train) ** 0.5)",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": "__________________________________________________________________________________________________\nLayer (type)                    Output Shape         Param #     Connected to                     \n==================================================================================================\ninput_1 (InputLayer)            (None, 1)            0                                            \n__________________________________________________________________________________________________\ninput_2 (InputLayer)            (None, 1)            0                                            \n__________________________________________________________________________________________________\ninput_3 (InputLayer)            (None, 1)            0                                            \n__________________________________________________________________________________________________\ninput_4 (InputLayer)            (None, 1)            0                                            \n__________________________________________________________________________________________________\ninput_5 (InputLayer)            (None, 1)            0                                            \n__________________________________________________________________________________________________\nembedding_1 (Embedding)         (None, 1, 2)         10          input_1[0][0]                    \n__________________________________________________________________________________________________\nembedding_2 (Embedding)         (None, 1, 1)         3           input_2[0][0]                    \n__________________________________________________________________________________________________\nembedding_3 (Embedding)         (None, 1, 1)         2           input_3[0][0]                    \n__________________________________________________________________________________________________\nembedding_4 (Embedding)         (None, 1, 3)         24          input_4[0][0]                    \n__________________________________________________________________________________________________\nembedding_5 (Embedding)         (None, 1, 4)         48          input_5[0][0]                    \n__________________________________________________________________________________________________\ninput_6 (InputLayer)            (None, 73)           0                                            \n__________________________________________________________________________________________________\nreshape_1 (Reshape)             (None, 2)            0           embedding_1[0][0]                \n__________________________________________________________________________________________________\nreshape_2 (Reshape)             (None, 1)            0           embedding_2[0][0]                \n__________________________________________________________________________________________________\nreshape_3 (Reshape)             (None, 1)            0           embedding_3[0][0]                \n__________________________________________________________________________________________________\nreshape_4 (Reshape)             (None, 3)            0           embedding_4[0][0]                \n__________________________________________________________________________________________________\nreshape_5 (Reshape)             (None, 4)            0           embedding_5[0][0]                \n__________________________________________________________________________________________________\nconcatenate_2 (Concatenate)     (None, 84)           0           input_6[0][0]                    \n                                                                 reshape_1[0][0]                  \n                                                                 reshape_2[0][0]                  \n                                                                 reshape_3[0][0]                  \n                                                                 reshape_4[0][0]                  \n                                                                 reshape_5[0][0]                  \n__________________________________________________________________________________________________\nbatch_normalization_3 (BatchNor (None, 84)           336         concatenate_2[0][0]              \n__________________________________________________________________________________________________\ndense_6 (Dense)                 (None, 10)           850         batch_normalization_3[0][0]      \n__________________________________________________________________________________________________\ndense_7 (Dense)                 (None, 10)           110         dense_6[0][0]                    \n__________________________________________________________________________________________________\ndropout_3 (Dropout)             (None, 10)           0           dense_7[0][0]                    \n__________________________________________________________________________________________________\nbatch_normalization_4 (BatchNor (None, 10)           40          dropout_3[0][0]                  \n__________________________________________________________________________________________________\ndense_8 (Dense)                 (None, 10)           110         batch_normalization_4[0][0]      \n__________________________________________________________________________________________________\ndense_9 (Dense)                 (None, 10)           110         dense_8[0][0]                    \n__________________________________________________________________________________________________\ndropout_4 (Dropout)             (None, 10)           0           dense_9[0][0]                    \n__________________________________________________________________________________________________\ndense_10 (Dense)                (None, 1)            11          dropout_4[0][0]                  \n==================================================================================================\nTotal params: 1,654\nTrainable params: 1,466\nNon-trainable params: 188\n__________________________________________________________________________________________________\nNone\n",
          "name": "stdout"
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.6",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}