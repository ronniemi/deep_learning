{
  "cells": [
    {
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true
      },
      "cell_type": "code",
      "source": "# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nfrom keras.models import Model\nfrom keras.layers import *\nfrom keras.callbacks import *\nfrom keras.regularizers import l2\nfrom keras.optimizers import *\nfrom keras.utils import to_categorical\nimport datetime\nfrom sklearn.preprocessing import LabelEncoder\nimport gc\nfrom sklearn.model_selection import train_test_split\nimport lightgbm as lgb\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.model_selection import KFold,StratifiedKFold\nfrom keras import backend as K\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Using TensorFlow backend.\n",
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": "['train.csv', 'merchants.csv', 'sample_submission.csv', 'test.csv', 'historical_transactions.csv', 'Data_Dictionary.xlsx', 'new_merchant_transactions.csv']\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "_uuid": "86cae6aa917478a27cd397d7dcc949447e696e5e"
      },
      "cell_type": "markdown",
      "source": "# Define global functions"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "4f4a12768f717d1dbf1671bdae5021816b60dd1e"
      },
      "cell_type": "code",
      "source": "# define function to reduce memory usage\ndef reduce_mem_usage(df, verbose=True):\n    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n    start_mem = df.memory_usage().sum() / 1024**2    \n    for col in df.columns:\n        col_type = df[col].dtypes\n        if col_type in numerics:\n            c_min = df[col].min()\n            c_max = df[col].max()\n            if str(col_type)[:3] == 'int':\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)  \n            else:\n                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n                    df[col] = df[col].astype(np.float16)\n                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    df[col] = df[col].astype(np.float64)    \n    end_mem = df.memory_usage().sum() / 1024**2\n    if verbose: print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(end_mem, 100 * (start_mem - end_mem) / start_mem))\n    return df\n\n# define function that calaculate RMSE\ndef root_mean_squared_error(y_true, y_pred):\n        return K.sqrt(K.mean(K.square(y_pred - y_true))) ",
      "execution_count": 2,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "d9f7ce14f675a7fb562e70187ca409b14db27d3e"
      },
      "cell_type": "markdown",
      "source": "# Read data"
    },
    {
      "metadata": {
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "trusted": true,
        "scrolled": false
      },
      "cell_type": "code",
      "source": "train_set = pd.read_csv(\"../input/train.csv\", parse_dates=[\"first_active_month\"])\ntest_set = pd.read_csv(\"../input/test.csv\", parse_dates=[\"first_active_month\"])\nhistory_trx = pd.read_csv(\"../input/historical_transactions.csv\", parse_dates=['purchase_date'])\nnew_trx = pd.read_csv(\"../input/new_merchant_transactions.csv\", parse_dates=['purchase_date'])\nmerchants_set = pd.read_csv(\"../input/merchants.csv\")\n\nprint(\"shape of train : \",train_set.shape)\nprint(\"shape of test : \",test_set.shape)\nprint(\"shape of history_trx : \",history_trx.shape)\nprint(\"shape of new_trx : \",new_trx.shape)\nprint(\"shape of merchants : \",merchants_set.shape)",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": "shape of train :  (201917, 6)\nshape of test :  (123623, 5)\nshape of history_trx :  (29112361, 14)\nshape of new_trx :  (1963031, 14)\nshape of merchants :  (334696, 22)\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "_uuid": "4bdb9744aa760f20ff42eef26f9a8e037e4ee955"
      },
      "cell_type": "markdown",
      "source": "# Feature extrection - collect information per card to form card_id profile"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "e1ae4cd8e747a22cd1cc955179713c2a199a1a80"
      },
      "cell_type": "code",
      "source": "# add 'year', 'month', and 'elepsed_time' features to the dataframe\nfor df in [train_set, test_set]:\n    df['year'] = df['first_active_month'].dt.year\n    df['month'] = df['first_active_month'].dt.month\n    df['elapsed_time'] = (datetime.date(2018, 2, 1) - df['first_active_month'].dt.date).dt.days # 1/2/2018 is the max date in train set\n    \n# create set of columns name that is numeric\nnumeric_col = ['elapsed_time']\n\n# split the train set to features and target\ntarget = train_set['target']\ndel train_set['target']",
      "execution_count": 4,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "531ab3c6752bd71966845bc98cb46c8c194ef322"
      },
      "cell_type": "code",
      "source": "# define aggregation function that collect information from data features to crate profile to each card_id\ndef agg_data_trx(trx_data, col_name):\n    \n    trx_data['authorized_flag'] = trx_data['authorized_flag'].map({'Y':1, 'N':0})\n    \n    trx_data['purchase_month'] = trx_data['purchase_date'].dt.month\n    \n    trx_data['month_diff'] = ((datetime.datetime.today() - trx_data['purchase_date']).dt.days)//30\n    trx_data['month_diff'] += trx_data['month_lag']\n    \n    trx_data = reduce_mem_usage(trx_data)\n    \n    trx_data.loc[:, 'purchase_date'] = pd.DatetimeIndex(trx_data['purchase_date']).astype(np.int64) * 1e-9\n    \n    agg_func = {\n        'merchant_id': ['nunique'],\n        'merchant_category_id': ['nunique'],\n        'state_id': ['nunique'],\n        'city_id': ['nunique'],\n        'subsector_id': ['nunique'],\n        'purchase_amount': ['sum', 'mean', 'max', 'min', 'std'],\n        'installments': ['sum', 'mean', 'max', 'min', 'std'],\n        'purchase_date': [np.ptp, 'min', 'max'],\n        'month_lag': ['mean', 'max', 'min', 'std'],\n        'month_diff': ['mean']\n    }\n    \n    agg_data = trx_data.groupby(['card_id']).agg(agg_func)\n    agg_data.columns = [col_name + '_' + '_'.join(col).strip() for col in agg_data.columns.values]\n    agg_data.reset_index(inplace=True)\n    \n    df = (trx_data.groupby('card_id').size().reset_index(name=col_name + '_trx_count'))\n    \n    agg_data = pd.merge(df, agg_data, on='card_id', how='left')\n    \n    agg_numeric_col = [col for col in agg_data.columns if col not in ['card_id']]\n    numeric_col.extend(agg_numeric_col)\n    \n    return agg_data\n\nhistory_trx_per_card = agg_data_trx(history_trx, 'history')\nnew_trx_per_card = agg_data_trx(new_trx, 'new')\n\n\n# merge the new features for each card_id with the 3 basic features in train set and test set\ntrain_set = pd.merge(train_set, history_trx_per_card, on='card_id', how='left')\ntest_set = pd.merge(test_set, history_trx_per_card, on='card_id', how='left')\n\ntrain_set = pd.merge(train_set, new_trx_per_card, on='card_id', how='left')\ntest_set = pd.merge(test_set, new_trx_per_card, on='card_id', how='left')\n\n# delete unnecessary dataframes to reduce memory usage\ndel history_trx_per_card\ndel new_trx_per_card\ngc.collect()\n\n# remove nan values from data set\ntrain_set_no_nan = train_set.fillna(-1)\ntest_set_no_nan = train_set.fillna(-1)\n\n# define the columns that are going to enter to the model\nused_col = train_set.columns\nused_col =  [col for col in used_col if col not in ['card_id', 'first_active_month']]",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Mem. usage decreased to 1610.30 Mb (54.7% reduction)\nMem. usage decreased to 104.84 Mb (56.2% reduction)\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "_uuid": "17cc95098cb7021f7c27e06377faa737a691e609"
      },
      "cell_type": "markdown",
      "source": "# Preprocessing"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "1d3acabadd460ac980fc5026588db84eaa0e69cd"
      },
      "cell_type": "code",
      "source": "cat_col = train_set.columns\ncat_col = [col for col in cat_col if col not in np.concatenate((['card_id', 'first_active_month'], numeric_col), axis=0)]\n\nnumeric_col =  [col for col in numeric_col if col not in ['card_id', 'first_active_month']]",
      "execution_count": 6,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "c47482796675c87a0438f4a6a96a801d3482c901"
      },
      "cell_type": "code",
      "source": "def preprocess(trx_data):\n    for cat_col_name in cat_col:\n        lbl = LabelEncoder()\n        lbl.fit(trx_data[cat_col_name].unique().astype('str'))\n        trx_data[cat_col_name] = lbl.transform(trx_data[cat_col_name].astype('str'))\n    \n    for numeric_col_name in numeric_col:\n        trx_data[numeric_col_name] = pd.to_numeric(trx_data[numeric_col_name])\n        min_val = trx_data[numeric_col_name].min()\n        max_val = trx_data[numeric_col_name].max()\n        if min_val == max_val:\n            trx_data[numeric_col_name] = 0\n            print(numeric_col_name)\n        else:\n            trx_data[numeric_col_name] = (max_val - trx_data[numeric_col_name]) / (max_val - min_val)\n\n    return trx_data\n\ntrain_set = preprocess(train_set_no_nan)\ntest_set = preprocess(test_set_no_nan)",
      "execution_count": 7,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "b8820d16aa7ff4436da1ce37cae24f50f5876524"
      },
      "cell_type": "code",
      "source": "train_set.head()",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 8,
          "data": {
            "text/plain": "  first_active_month         ...         new_month_diff_mean\n0         2017-06-01         ...                    0.534972\n1         2017-01-01         ...                    0.485507\n2         2016-08-01         ...                    0.565217\n3         2017-09-01         ...                    0.527950\n4         2017-11-01         ...                    0.531401\n\n[5 rows x 56 columns]",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>first_active_month</th>\n      <th>card_id</th>\n      <th>feature_1</th>\n      <th>feature_2</th>\n      <th>feature_3</th>\n      <th>year</th>\n      <th>month</th>\n      <th>elapsed_time</th>\n      <th>history_trx_count</th>\n      <th>history_merchant_id_nunique</th>\n      <th>history_merchant_category_id_nunique</th>\n      <th>history_state_id_nunique</th>\n      <th>history_city_id_nunique</th>\n      <th>history_subsector_id_nunique</th>\n      <th>history_purchase_amount_sum</th>\n      <th>history_purchase_amount_mean</th>\n      <th>history_purchase_amount_max</th>\n      <th>history_purchase_amount_min</th>\n      <th>history_purchase_amount_std</th>\n      <th>history_installments_sum</th>\n      <th>history_installments_mean</th>\n      <th>history_installments_max</th>\n      <th>history_installments_min</th>\n      <th>history_installments_std</th>\n      <th>history_purchase_date_ptp</th>\n      <th>history_purchase_date_min</th>\n      <th>history_purchase_date_max</th>\n      <th>history_month_lag_mean</th>\n      <th>history_month_lag_max</th>\n      <th>history_month_lag_min</th>\n      <th>history_month_lag_std</th>\n      <th>history_month_diff_mean</th>\n      <th>new_trx_count</th>\n      <th>new_merchant_id_nunique</th>\n      <th>new_merchant_category_id_nunique</th>\n      <th>new_state_id_nunique</th>\n      <th>new_city_id_nunique</th>\n      <th>new_subsector_id_nunique</th>\n      <th>new_purchase_amount_sum</th>\n      <th>new_purchase_amount_mean</th>\n      <th>new_purchase_amount_max</th>\n      <th>new_purchase_amount_min</th>\n      <th>new_purchase_amount_std</th>\n      <th>new_installments_sum</th>\n      <th>new_installments_mean</th>\n      <th>new_installments_max</th>\n      <th>new_installments_min</th>\n      <th>new_installments_std</th>\n      <th>new_purchase_date_ptp</th>\n      <th>new_purchase_date_min</th>\n      <th>new_purchase_date_max</th>\n      <th>new_month_lag_mean</th>\n      <th>new_month_lag_max</th>\n      <th>new_month_lag_min</th>\n      <th>new_month_lag_std</th>\n      <th>new_month_diff_mean</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2017-06-01</td>\n      <td>C_ID_92a2005557</td>\n      <td>4</td>\n      <td>1</td>\n      <td>1</td>\n      <td>6</td>\n      <td>8</td>\n      <td>0.892732</td>\n      <td>0.911340</td>\n      <td>0.765743</td>\n      <td>0.574468</td>\n      <td>0.894737</td>\n      <td>0.909091</td>\n      <td>0.393939</td>\n      <td>0.999680</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>0.999744</td>\n      <td>1.000000</td>\n      <td>0.994633</td>\n      <td>0.991154</td>\n      <td>0.998999</td>\n      <td>0.909091</td>\n      <td>0.999554</td>\n      <td>0.429034</td>\n      <td>0.513389</td>\n      <td>0.009176</td>\n      <td>0.313297</td>\n      <td>0.0</td>\n      <td>0.583333</td>\n      <td>0.669152</td>\n      <td>0.943195</td>\n      <td>0.781818</td>\n      <td>0.781818</td>\n      <td>0.634146</td>\n      <td>0.866667</td>\n      <td>0.862069</td>\n      <td>0.56</td>\n      <td>0.679688</td>\n      <td>0.990234</td>\n      <td>0.991211</td>\n      <td>0.993652</td>\n      <td>0.976562</td>\n      <td>0.994059</td>\n      <td>0.971926</td>\n      <td>0.999</td>\n      <td>0.923077</td>\n      <td>0.994637</td>\n      <td>0.112546</td>\n      <td>0.003195</td>\n      <td>0.000086</td>\n      <td>0.173913</td>\n      <td>0.0</td>\n      <td>0.333333</td>\n      <td>0.115021</td>\n      <td>0.534972</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2017-01-01</td>\n      <td>C_ID_3d0044924f</td>\n      <td>3</td>\n      <td>0</td>\n      <td>0</td>\n      <td>6</td>\n      <td>0</td>\n      <td>0.826620</td>\n      <td>0.880412</td>\n      <td>0.644836</td>\n      <td>0.404255</td>\n      <td>0.894737</td>\n      <td>0.878788</td>\n      <td>0.303030</td>\n      <td>0.999688</td>\n      <td>1.000000</td>\n      <td>0.999999</td>\n      <td>0.999846</td>\n      <td>1.000000</td>\n      <td>0.772089</td>\n      <td>0.971953</td>\n      <td>0.989990</td>\n      <td>1.000000</td>\n      <td>0.994533</td>\n      <td>0.079760</td>\n      <td>0.984417</td>\n      <td>0.071463</td>\n      <td>0.403338</td>\n      <td>0.0</td>\n      <td>0.916667</td>\n      <td>0.464546</td>\n      <td>0.867692</td>\n      <td>0.936364</td>\n      <td>0.936364</td>\n      <td>0.853659</td>\n      <td>0.866667</td>\n      <td>0.931034</td>\n      <td>0.80</td>\n      <td>0.630371</td>\n      <td>0.993652</td>\n      <td>0.996094</td>\n      <td>0.994629</td>\n      <td>0.979492</td>\n      <td>0.988119</td>\n      <td>0.943853</td>\n      <td>0.998</td>\n      <td>0.846154</td>\n      <td>0.994637</td>\n      <td>0.085351</td>\n      <td>0.005001</td>\n      <td>0.001797</td>\n      <td>0.166667</td>\n      <td>0.0</td>\n      <td>0.333333</td>\n      <td>0.093365</td>\n      <td>0.485507</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2016-08-01</td>\n      <td>C_ID_d639edf6cd</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>5</td>\n      <td>10</td>\n      <td>0.759632</td>\n      <td>0.985911</td>\n      <td>0.969773</td>\n      <td>0.925532</td>\n      <td>0.947368</td>\n      <td>0.939394</td>\n      <td>0.818182</td>\n      <td>0.999658</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>0.999428</td>\n      <td>1.000000</td>\n      <td>0.996284</td>\n      <td>0.991346</td>\n      <td>1.000000</td>\n      <td>0.909091</td>\n      <td>1.000000</td>\n      <td>0.027178</td>\n      <td>0.971646</td>\n      <td>0.003062</td>\n      <td>0.690634</td>\n      <td>0.0</td>\n      <td>1.000000</td>\n      <td>0.459013</td>\n      <td>0.944544</td>\n      <td>0.981818</td>\n      <td>0.981818</td>\n      <td>0.951220</td>\n      <td>0.866667</td>\n      <td>0.931034</td>\n      <td>0.92</td>\n      <td>0.609863</td>\n      <td>0.993164</td>\n      <td>0.996094</td>\n      <td>0.993164</td>\n      <td>1.000000</td>\n      <td>0.994059</td>\n      <td>0.971926</td>\n      <td>0.999</td>\n      <td>0.923077</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>0.000127</td>\n      <td>0.000128</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>0.565217</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2017-09-01</td>\n      <td>C_ID_186d6a6901</td>\n      <td>3</td>\n      <td>2</td>\n      <td>0</td>\n      <td>6</td>\n      <td>11</td>\n      <td>0.933012</td>\n      <td>0.974227</td>\n      <td>0.876574</td>\n      <td>0.744681</td>\n      <td>0.789474</td>\n      <td>0.909091</td>\n      <td>0.636364</td>\n      <td>0.999661</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>0.999795</td>\n      <td>1.000000</td>\n      <td>0.961602</td>\n      <td>0.977710</td>\n      <td>0.996997</td>\n      <td>1.000000</td>\n      <td>0.997869</td>\n      <td>0.637469</td>\n      <td>0.263813</td>\n      <td>0.001300</td>\n      <td>0.226432</td>\n      <td>0.0</td>\n      <td>0.333333</td>\n      <td>0.755752</td>\n      <td>0.952048</td>\n      <td>0.927273</td>\n      <td>0.927273</td>\n      <td>0.829268</td>\n      <td>0.800000</td>\n      <td>0.896552</td>\n      <td>0.76</td>\n      <td>0.631836</td>\n      <td>0.992188</td>\n      <td>0.994141</td>\n      <td>0.994629</td>\n      <td>0.978027</td>\n      <td>0.989109</td>\n      <td>0.951874</td>\n      <td>0.998</td>\n      <td>1.000000</td>\n      <td>0.990584</td>\n      <td>0.321539</td>\n      <td>0.003087</td>\n      <td>0.000710</td>\n      <td>0.095238</td>\n      <td>0.0</td>\n      <td>0.333333</td>\n      <td>0.128379</td>\n      <td>0.527950</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2017-11-01</td>\n      <td>C_ID_cdbd2c0db2</td>\n      <td>0</td>\n      <td>2</td>\n      <td>0</td>\n      <td>6</td>\n      <td>2</td>\n      <td>0.959720</td>\n      <td>0.954983</td>\n      <td>0.836272</td>\n      <td>0.734043</td>\n      <td>0.736842</td>\n      <td>0.924242</td>\n      <td>0.515152</td>\n      <td>0.999661</td>\n      <td>0.999999</td>\n      <td>0.999999</td>\n      <td>0.999974</td>\n      <td>0.999999</td>\n      <td>0.921140</td>\n      <td>0.974241</td>\n      <td>0.987988</td>\n      <td>0.818182</td>\n      <td>0.993136</td>\n      <td>0.746303</td>\n      <td>0.136902</td>\n      <td>0.000352</td>\n      <td>0.102174</td>\n      <td>0.0</td>\n      <td>0.166667</td>\n      <td>0.868486</td>\n      <td>0.951995</td>\n      <td>0.663636</td>\n      <td>0.663636</td>\n      <td>0.560976</td>\n      <td>0.600000</td>\n      <td>0.793103</td>\n      <td>0.56</td>\n      <td>0.716797</td>\n      <td>0.990234</td>\n      <td>0.981445</td>\n      <td>0.994629</td>\n      <td>0.974609</td>\n      <td>0.959406</td>\n      <td>0.944633</td>\n      <td>0.997</td>\n      <td>1.000000</td>\n      <td>0.992616</td>\n      <td>0.073739</td>\n      <td>0.003370</td>\n      <td>0.000125</td>\n      <td>0.148148</td>\n      <td>0.0</td>\n      <td>0.333333</td>\n      <td>0.119005</td>\n      <td>0.531401</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "_uuid": "0eaf388d25ace39a6f781d532ead2e802ff78946"
      },
      "cell_type": "markdown",
      "source": "# split the given train set to train and test set"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "b5f97a5ce3daac2ef4caf508bd4692a2d6cd67d6"
      },
      "cell_type": "code",
      "source": "X_train, X_test, y_train, y_test = train_test_split(train_set, target, test_size=0.2, random_state=24)",
      "execution_count": 9,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "36f2637137c36cce1469d765b4fcffe9aa3cb2ba"
      },
      "cell_type": "code",
      "source": "print('X_train shape', X_train.shape)\nprint('X_test shape', X_test.shape)",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": "X_train shape (161533, 56)\nX_test shape (40384, 56)\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "9850d2457758c360bb8b51ed8e03ec87e26d2f05"
      },
      "cell_type": "code",
      "source": "X_train.head()",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 11,
          "data": {
            "text/plain": "       first_active_month         ...         new_month_diff_mean\n165743         2017-06-01         ...                    0.539855\n119952         2017-11-01         ...                    0.532234\n89339          2017-09-01         ...                    0.521739\n25589          2014-05-01         ...                    0.565217\n162026         2017-10-01         ...                    0.527950\n\n[5 rows x 56 columns]",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>first_active_month</th>\n      <th>card_id</th>\n      <th>feature_1</th>\n      <th>feature_2</th>\n      <th>feature_3</th>\n      <th>year</th>\n      <th>month</th>\n      <th>elapsed_time</th>\n      <th>history_trx_count</th>\n      <th>history_merchant_id_nunique</th>\n      <th>history_merchant_category_id_nunique</th>\n      <th>history_state_id_nunique</th>\n      <th>history_city_id_nunique</th>\n      <th>history_subsector_id_nunique</th>\n      <th>history_purchase_amount_sum</th>\n      <th>history_purchase_amount_mean</th>\n      <th>history_purchase_amount_max</th>\n      <th>history_purchase_amount_min</th>\n      <th>history_purchase_amount_std</th>\n      <th>history_installments_sum</th>\n      <th>history_installments_mean</th>\n      <th>history_installments_max</th>\n      <th>history_installments_min</th>\n      <th>history_installments_std</th>\n      <th>history_purchase_date_ptp</th>\n      <th>history_purchase_date_min</th>\n      <th>history_purchase_date_max</th>\n      <th>history_month_lag_mean</th>\n      <th>history_month_lag_max</th>\n      <th>history_month_lag_min</th>\n      <th>history_month_lag_std</th>\n      <th>history_month_diff_mean</th>\n      <th>new_trx_count</th>\n      <th>new_merchant_id_nunique</th>\n      <th>new_merchant_category_id_nunique</th>\n      <th>new_state_id_nunique</th>\n      <th>new_city_id_nunique</th>\n      <th>new_subsector_id_nunique</th>\n      <th>new_purchase_amount_sum</th>\n      <th>new_purchase_amount_mean</th>\n      <th>new_purchase_amount_max</th>\n      <th>new_purchase_amount_min</th>\n      <th>new_purchase_amount_std</th>\n      <th>new_installments_sum</th>\n      <th>new_installments_mean</th>\n      <th>new_installments_max</th>\n      <th>new_installments_min</th>\n      <th>new_installments_std</th>\n      <th>new_purchase_date_ptp</th>\n      <th>new_purchase_date_min</th>\n      <th>new_purchase_date_max</th>\n      <th>new_month_lag_mean</th>\n      <th>new_month_lag_max</th>\n      <th>new_month_lag_min</th>\n      <th>new_month_lag_std</th>\n      <th>new_month_diff_mean</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>165743</th>\n      <td>2017-06-01</td>\n      <td>C_ID_f9f784f2e2</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>6</td>\n      <td>8</td>\n      <td>0.892732</td>\n      <td>0.918213</td>\n      <td>0.798489</td>\n      <td>0.574468</td>\n      <td>0.947368</td>\n      <td>0.878788</td>\n      <td>0.454545</td>\n      <td>0.999679</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>0.999544</td>\n      <td>1.000000</td>\n      <td>0.874071</td>\n      <td>0.975929</td>\n      <td>0.989990</td>\n      <td>1.000000</td>\n      <td>0.996176</td>\n      <td>0.387759</td>\n      <td>0.551730</td>\n      <td>0.000438</td>\n      <td>0.264798</td>\n      <td>0.000000</td>\n      <td>0.583333</td>\n      <td>0.642373</td>\n      <td>0.943269</td>\n      <td>0.881818</td>\n      <td>0.881818</td>\n      <td>0.780488</td>\n      <td>0.866667</td>\n      <td>0.862069</td>\n      <td>0.68</td>\n      <td>0.651855</td>\n      <td>0.993164</td>\n      <td>0.995117</td>\n      <td>0.993652</td>\n      <td>0.978516</td>\n      <td>0.981188</td>\n      <td>0.941513</td>\n      <td>0.997</td>\n      <td>0.846154</td>\n      <td>0.993089</td>\n      <td>0.066801</td>\n      <td>0.003361</td>\n      <td>0.000092</td>\n      <td>0.222222</td>\n      <td>0.0</td>\n      <td>0.333333</td>\n      <td>0.125792</td>\n      <td>0.539855</td>\n    </tr>\n    <tr>\n      <th>119952</th>\n      <td>2017-11-01</td>\n      <td>C_ID_c36d60df2c</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>6</td>\n      <td>2</td>\n      <td>0.959720</td>\n      <td>0.970790</td>\n      <td>0.899244</td>\n      <td>0.744681</td>\n      <td>0.842105</td>\n      <td>0.939394</td>\n      <td>0.575758</td>\n      <td>0.999661</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>0.999528</td>\n      <td>1.000000</td>\n      <td>0.960363</td>\n      <td>0.978846</td>\n      <td>0.996997</td>\n      <td>1.000000</td>\n      <td>0.998540</td>\n      <td>0.774618</td>\n      <td>0.110719</td>\n      <td>0.006458</td>\n      <td>0.106003</td>\n      <td>0.000000</td>\n      <td>0.166667</td>\n      <td>0.863084</td>\n      <td>0.959328</td>\n      <td>0.727273</td>\n      <td>0.727273</td>\n      <td>0.463415</td>\n      <td>0.600000</td>\n      <td>0.793103</td>\n      <td>0.44</td>\n      <td>0.645996</td>\n      <td>0.983398</td>\n      <td>0.918945</td>\n      <td>0.993652</td>\n      <td>0.953613</td>\n      <td>0.952475</td>\n      <td>0.931268</td>\n      <td>0.989</td>\n      <td>0.846154</td>\n      <td>0.985507</td>\n      <td>0.040831</td>\n      <td>0.003376</td>\n      <td>0.000016</td>\n      <td>0.218391</td>\n      <td>0.0</td>\n      <td>0.333333</td>\n      <td>0.130854</td>\n      <td>0.532234</td>\n    </tr>\n    <tr>\n      <th>89339</th>\n      <td>2017-09-01</td>\n      <td>C_ID_42699e8b0c</td>\n      <td>3</td>\n      <td>0</td>\n      <td>0</td>\n      <td>6</td>\n      <td>11</td>\n      <td>0.933012</td>\n      <td>0.988316</td>\n      <td>0.989924</td>\n      <td>0.946809</td>\n      <td>0.947368</td>\n      <td>0.984848</td>\n      <td>0.878788</td>\n      <td>0.999656</td>\n      <td>1.000000</td>\n      <td>0.999999</td>\n      <td>0.999846</td>\n      <td>1.000000</td>\n      <td>0.970273</td>\n      <td>0.969471</td>\n      <td>0.987988</td>\n      <td>0.818182</td>\n      <td>0.990392</td>\n      <td>0.617788</td>\n      <td>0.285263</td>\n      <td>0.000077</td>\n      <td>0.217673</td>\n      <td>0.000000</td>\n      <td>0.333333</td>\n      <td>0.744954</td>\n      <td>0.976496</td>\n      <td>0.972727</td>\n      <td>0.972727</td>\n      <td>0.926829</td>\n      <td>0.800000</td>\n      <td>0.896552</td>\n      <td>0.88</td>\n      <td>0.589355</td>\n      <td>0.944824</td>\n      <td>0.959961</td>\n      <td>0.958008</td>\n      <td>0.961914</td>\n      <td>0.983168</td>\n      <td>0.817522</td>\n      <td>0.987</td>\n      <td>1.000000</td>\n      <td>0.945342</td>\n      <td>0.771859</td>\n      <td>0.002342</td>\n      <td>0.001544</td>\n      <td>0.166667</td>\n      <td>0.0</td>\n      <td>0.333333</td>\n      <td>0.000000</td>\n      <td>0.521739</td>\n    </tr>\n    <tr>\n      <th>25589</th>\n      <td>2014-05-01</td>\n      <td>C_ID_750614dd76</td>\n      <td>2</td>\n      <td>2</td>\n      <td>1</td>\n      <td>3</td>\n      <td>7</td>\n      <td>0.399299</td>\n      <td>0.992440</td>\n      <td>0.959698</td>\n      <td>0.882979</td>\n      <td>0.947368</td>\n      <td>0.954545</td>\n      <td>0.696970</td>\n      <td>0.999655</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>0.999913</td>\n      <td>1.000000</td>\n      <td>0.996284</td>\n      <td>0.991346</td>\n      <td>1.000000</td>\n      <td>0.909091</td>\n      <td>1.000000</td>\n      <td>0.218255</td>\n      <td>0.825824</td>\n      <td>0.072956</td>\n      <td>0.424262</td>\n      <td>0.090909</td>\n      <td>0.833333</td>\n      <td>0.531786</td>\n      <td>0.942308</td>\n      <td>0.981818</td>\n      <td>0.981818</td>\n      <td>0.951220</td>\n      <td>0.866667</td>\n      <td>0.931034</td>\n      <td>0.92</td>\n      <td>0.610352</td>\n      <td>0.993652</td>\n      <td>0.996582</td>\n      <td>0.993652</td>\n      <td>1.000000</td>\n      <td>0.994059</td>\n      <td>0.971926</td>\n      <td>0.999</td>\n      <td>0.923077</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>0.000013</td>\n      <td>0.000014</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>0.565217</td>\n    </tr>\n    <tr>\n      <th>162026</th>\n      <td>2017-10-01</td>\n      <td>C_ID_18d2ec30fc</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>6</td>\n      <td>1</td>\n      <td>0.946147</td>\n      <td>0.967698</td>\n      <td>0.889169</td>\n      <td>0.755319</td>\n      <td>0.842105</td>\n      <td>0.924242</td>\n      <td>0.575758</td>\n      <td>0.999644</td>\n      <td>0.999997</td>\n      <td>0.999998</td>\n      <td>0.999564</td>\n      <td>0.999998</td>\n      <td>0.922378</td>\n      <td>0.968039</td>\n      <td>0.989990</td>\n      <td>1.000000</td>\n      <td>0.992489</td>\n      <td>0.675289</td>\n      <td>0.231007</td>\n      <td>0.011469</td>\n      <td>0.142854</td>\n      <td>0.000000</td>\n      <td>0.250000</td>\n      <td>0.812234</td>\n      <td>0.943910</td>\n      <td>0.863636</td>\n      <td>0.863636</td>\n      <td>0.682927</td>\n      <td>0.733333</td>\n      <td>0.758621</td>\n      <td>0.48</td>\n      <td>0.617676</td>\n      <td>0.981445</td>\n      <td>0.958008</td>\n      <td>0.994629</td>\n      <td>0.958496</td>\n      <td>0.964356</td>\n      <td>0.911769</td>\n      <td>0.987</td>\n      <td>1.000000</td>\n      <td>0.976078</td>\n      <td>0.191936</td>\n      <td>0.003150</td>\n      <td>0.000319</td>\n      <td>0.166667</td>\n      <td>0.0</td>\n      <td>0.333333</td>\n      <td>0.110264</td>\n      <td>0.527950</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "682f203392416f8cb07e16899d72721e5044138c"
      },
      "cell_type": "code",
      "source": "X_test.head()",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 12,
          "data": {
            "text/plain": "       first_active_month         ...         new_month_diff_mean\n110727         2017-12-01         ...                    1.000000\n108935         2017-02-01         ...                    0.534161\n22893          2017-09-01         ...                    0.521739\n79140          2016-04-01         ...                    0.528986\n12651          2017-06-01         ...                    0.304348\n\n[5 rows x 56 columns]",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>first_active_month</th>\n      <th>card_id</th>\n      <th>feature_1</th>\n      <th>feature_2</th>\n      <th>feature_3</th>\n      <th>year</th>\n      <th>month</th>\n      <th>elapsed_time</th>\n      <th>history_trx_count</th>\n      <th>history_merchant_id_nunique</th>\n      <th>history_merchant_category_id_nunique</th>\n      <th>history_state_id_nunique</th>\n      <th>history_city_id_nunique</th>\n      <th>history_subsector_id_nunique</th>\n      <th>history_purchase_amount_sum</th>\n      <th>history_purchase_amount_mean</th>\n      <th>history_purchase_amount_max</th>\n      <th>history_purchase_amount_min</th>\n      <th>history_purchase_amount_std</th>\n      <th>history_installments_sum</th>\n      <th>history_installments_mean</th>\n      <th>history_installments_max</th>\n      <th>history_installments_min</th>\n      <th>history_installments_std</th>\n      <th>history_purchase_date_ptp</th>\n      <th>history_purchase_date_min</th>\n      <th>history_purchase_date_max</th>\n      <th>history_month_lag_mean</th>\n      <th>history_month_lag_max</th>\n      <th>history_month_lag_min</th>\n      <th>history_month_lag_std</th>\n      <th>history_month_diff_mean</th>\n      <th>new_trx_count</th>\n      <th>new_merchant_id_nunique</th>\n      <th>new_merchant_category_id_nunique</th>\n      <th>new_state_id_nunique</th>\n      <th>new_city_id_nunique</th>\n      <th>new_subsector_id_nunique</th>\n      <th>new_purchase_amount_sum</th>\n      <th>new_purchase_amount_mean</th>\n      <th>new_purchase_amount_max</th>\n      <th>new_purchase_amount_min</th>\n      <th>new_purchase_amount_std</th>\n      <th>new_installments_sum</th>\n      <th>new_installments_mean</th>\n      <th>new_installments_max</th>\n      <th>new_installments_min</th>\n      <th>new_installments_std</th>\n      <th>new_purchase_date_ptp</th>\n      <th>new_purchase_date_min</th>\n      <th>new_purchase_date_max</th>\n      <th>new_month_lag_mean</th>\n      <th>new_month_lag_max</th>\n      <th>new_month_lag_min</th>\n      <th>new_month_lag_std</th>\n      <th>new_month_diff_mean</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>110727</th>\n      <td>2017-12-01</td>\n      <td>C_ID_3d38c16da9</td>\n      <td>2</td>\n      <td>2</td>\n      <td>1</td>\n      <td>6</td>\n      <td>3</td>\n      <td>0.972855</td>\n      <td>0.997251</td>\n      <td>0.982368</td>\n      <td>0.946809</td>\n      <td>0.894737</td>\n      <td>0.954545</td>\n      <td>0.878788</td>\n      <td>0.999654</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.999949</td>\n      <td>1.0</td>\n      <td>0.990504</td>\n      <td>0.973846</td>\n      <td>0.996997</td>\n      <td>1.000000</td>\n      <td>0.994291</td>\n      <td>0.914627</td>\n      <td>0.010962</td>\n      <td>0.064263</td>\n      <td>0.063122</td>\n      <td>0.0</td>\n      <td>0.083333</td>\n      <td>0.884154</td>\n      <td>0.946154</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.00</td>\n      <td>0.611816</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>0.995050</td>\n      <td>1.000000</td>\n      <td>1.000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>108935</th>\n      <td>2017-02-01</td>\n      <td>C_ID_baa868fe6e</td>\n      <td>2</td>\n      <td>2</td>\n      <td>1</td>\n      <td>6</td>\n      <td>4</td>\n      <td>0.840193</td>\n      <td>0.951890</td>\n      <td>0.876574</td>\n      <td>0.765957</td>\n      <td>0.842105</td>\n      <td>0.939394</td>\n      <td>0.666667</td>\n      <td>0.999669</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.999913</td>\n      <td>1.0</td>\n      <td>0.914533</td>\n      <td>0.973917</td>\n      <td>0.991992</td>\n      <td>1.000000</td>\n      <td>0.996098</td>\n      <td>0.160892</td>\n      <td>0.845104</td>\n      <td>0.029205</td>\n      <td>0.386090</td>\n      <td>0.0</td>\n      <td>0.916667</td>\n      <td>0.597288</td>\n      <td>0.937161</td>\n      <td>0.927273</td>\n      <td>0.927273</td>\n      <td>0.829268</td>\n      <td>0.866667</td>\n      <td>0.931034</td>\n      <td>0.76</td>\n      <td>0.631836</td>\n      <td>0.992188</td>\n      <td>0.993652</td>\n      <td>0.993652</td>\n      <td>0.978027</td>\n      <td>0.987129</td>\n      <td>0.943853</td>\n      <td>0.996</td>\n      <td>1.000000</td>\n      <td>0.988445</td>\n      <td>0.258781</td>\n      <td>0.003080</td>\n      <td>0.000483</td>\n      <td>0.095238</td>\n      <td>0.000000</td>\n      <td>0.333333</td>\n      <td>0.128379</td>\n      <td>0.534161</td>\n    </tr>\n    <tr>\n      <th>22893</th>\n      <td>2017-09-01</td>\n      <td>C_ID_2ce1c19fa6</td>\n      <td>2</td>\n      <td>0</td>\n      <td>1</td>\n      <td>6</td>\n      <td>11</td>\n      <td>0.933012</td>\n      <td>0.978007</td>\n      <td>0.906801</td>\n      <td>0.765957</td>\n      <td>0.947368</td>\n      <td>0.954545</td>\n      <td>0.606061</td>\n      <td>0.999660</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.999846</td>\n      <td>1.0</td>\n      <td>0.994633</td>\n      <td>0.990589</td>\n      <td>0.998999</td>\n      <td>0.909091</td>\n      <td>0.999130</td>\n      <td>0.641601</td>\n      <td>0.312906</td>\n      <td>0.051371</td>\n      <td>0.185187</td>\n      <td>0.0</td>\n      <td>0.333333</td>\n      <td>0.778299</td>\n      <td>0.948718</td>\n      <td>0.963636</td>\n      <td>0.963636</td>\n      <td>0.902439</td>\n      <td>0.866667</td>\n      <td>0.896552</td>\n      <td>0.84</td>\n      <td>0.618164</td>\n      <td>0.993164</td>\n      <td>0.996094</td>\n      <td>0.993652</td>\n      <td>0.979492</td>\n      <td>0.994059</td>\n      <td>0.971926</td>\n      <td>0.999</td>\n      <td>0.923077</td>\n      <td>0.994637</td>\n      <td>0.935898</td>\n      <td>0.002672</td>\n      <td>0.002448</td>\n      <td>0.333333</td>\n      <td>0.333333</td>\n      <td>0.333333</td>\n      <td>0.414214</td>\n      <td>0.521739</td>\n    </tr>\n    <tr>\n      <th>79140</th>\n      <td>2016-04-01</td>\n      <td>C_ID_03a8c5345e</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>5</td>\n      <td>6</td>\n      <td>0.706217</td>\n      <td>0.960481</td>\n      <td>0.858942</td>\n      <td>0.648936</td>\n      <td>0.842105</td>\n      <td>0.909091</td>\n      <td>0.545455</td>\n      <td>0.999664</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.999718</td>\n      <td>1.0</td>\n      <td>0.995871</td>\n      <td>0.991239</td>\n      <td>0.998999</td>\n      <td>0.909091</td>\n      <td>0.999665</td>\n      <td>0.027905</td>\n      <td>0.987400</td>\n      <td>0.018485</td>\n      <td>0.552682</td>\n      <td>0.0</td>\n      <td>1.000000</td>\n      <td>0.371254</td>\n      <td>0.938856</td>\n      <td>0.936364</td>\n      <td>0.945455</td>\n      <td>0.829268</td>\n      <td>0.866667</td>\n      <td>0.896552</td>\n      <td>0.80</td>\n      <td>0.627441</td>\n      <td>0.991699</td>\n      <td>0.994141</td>\n      <td>0.993164</td>\n      <td>0.978027</td>\n      <td>0.994059</td>\n      <td>0.971926</td>\n      <td>0.999</td>\n      <td>0.923077</td>\n      <td>0.994637</td>\n      <td>0.527715</td>\n      <td>0.002589</td>\n      <td>0.000934</td>\n      <td>0.166667</td>\n      <td>0.000000</td>\n      <td>0.333333</td>\n      <td>0.093365</td>\n      <td>0.528986</td>\n    </tr>\n    <tr>\n      <th>12651</th>\n      <td>2017-06-01</td>\n      <td>C_ID_a51a3996c2</td>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>6</td>\n      <td>8</td>\n      <td>0.892732</td>\n      <td>0.976976</td>\n      <td>0.914358</td>\n      <td>0.776596</td>\n      <td>1.000000</td>\n      <td>0.939394</td>\n      <td>0.606061</td>\n      <td>0.999661</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.999795</td>\n      <td>1.0</td>\n      <td>0.996284</td>\n      <td>0.991346</td>\n      <td>1.000000</td>\n      <td>0.909091</td>\n      <td>1.000000</td>\n      <td>0.767201</td>\n      <td>0.565307</td>\n      <td>0.420992</td>\n      <td>0.101342</td>\n      <td>0.0</td>\n      <td>0.166667</td>\n      <td>0.856389</td>\n      <td>0.556299</td>\n      <td>0.927273</td>\n      <td>0.927273</td>\n      <td>0.853659</td>\n      <td>0.866667</td>\n      <td>0.896552</td>\n      <td>0.80</td>\n      <td>0.632812</td>\n      <td>0.993164</td>\n      <td>0.994141</td>\n      <td>0.994629</td>\n      <td>0.978027</td>\n      <td>0.994059</td>\n      <td>0.971926</td>\n      <td>0.999</td>\n      <td>0.923077</td>\n      <td>0.994637</td>\n      <td>0.566939</td>\n      <td>0.011330</td>\n      <td>0.009813</td>\n      <td>0.142857</td>\n      <td>0.000000</td>\n      <td>0.333333</td>\n      <td>0.101098</td>\n      <td>0.304348</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "_uuid": "565f7c63304115cdc8a6aaa3c5cddadd0b3c5ed2"
      },
      "cell_type": "markdown",
      "source": "# Classic ML model to form a benchmark"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "38e8bd0683b71e7af9264785787f34782e79ff8a"
      },
      "cell_type": "code",
      "source": "lgb_model = lgb.LGBMRegressor()\nlgb_model.fit(X_train[used_col], y_train.values)\n\nlgb_pred = lgb_model.predict(X_test[used_col])\n\nprint('RMSE:', mean_squared_error(y_test, lgb_pred) ** 0.5)",
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": "RMSE: 3.6071903156789533\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "_uuid": "7cefaf989f7496b60442ec4b32b278edc3b14410"
      },
      "cell_type": "markdown",
      "source": "# Create embedding to categorical feature"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "43185616539bf08f3eebd2c80a306940f23088b7"
      },
      "cell_type": "code",
      "source": "f1_unique_val = len(train_set['feature_1'].unique())\nf2_unique_val = len(train_set['feature_2'].unique())\nf3_unique_val = len(train_set['feature_3'].unique())\nyear_unique_val = len(train_set['year'].unique())\nmonth_unique_val = len(train_set['month'].unique())",
      "execution_count": 14,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "71ee8991faa513ee2ebe54ff0335848cd73be0a0"
      },
      "cell_type": "code",
      "source": "f1_inp = Input(shape=(1,),dtype='int64')\nf2_inp = Input(shape=(1,),dtype='int64')\nf3_inp = Input(shape=(1,),dtype='int64')\nyear_inp = Input(shape=(1,),dtype='int64')\nmonth_inp = Input(shape=(1,),dtype='int64')\n\nf1_emb = Embedding(f1_unique_val,2,input_length=1, embeddings_regularizer=l2(1e-6))(f1_inp)\nf2_emb = Embedding(f2_unique_val,1,input_length=1, embeddings_regularizer=l2(1e-6))(f2_inp)\nf3_emb = Embedding(f3_unique_val,1,input_length=1, embeddings_regularizer=l2(1e-6))(f3_inp)\nyear_emb = Embedding(year_unique_val,3,input_length=1, embeddings_regularizer=l2(1e-6))(year_inp)\nmonth_emb = Embedding(month_unique_val,4,input_length=1, embeddings_regularizer=l2(1e-6))(month_inp)",
      "execution_count": 15,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "b11848ae55fe9b65848541054fa47d90c913b8a6"
      },
      "cell_type": "markdown",
      "source": "# Predicting the target using only the categorical features embeddings"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "fa07722e76be13e0f6cd975da0d900b2d01d5c12"
      },
      "cell_type": "code",
      "source": "x = concatenate([f1_emb,f2_emb,f3_emb,year_emb,month_emb])\nx = Flatten()(x)\nx = BatchNormalization()(x)\nx = Dense(10,activation='relu')(x)\nx = Dense(10,activation='relu')(x)\nx = Dropout(0.4)(x)\nx = BatchNormalization()(x)\nx = Dense(10,activation='relu')(x)\nx = Dense(10,activation='relu')(x)\nx = Dropout(0.7)(x)\nx = Dense(1, activation='sigmoid')(x) #activation='linear'\nemb_model = Model([f1_inp,f2_inp,f3_inp,year_inp,month_inp],x)\n#emb_model.compile(loss='mse',optimizer='adam')\n\nemb_model.compile(optimizer=\"RMSProp\", loss=root_mean_squared_error)\n\nprint(emb_model.summary())\n\nemb_model.fit([X_train[col] for col in cat_col], y_train, epochs=5)\n\nemb_pred = emb_model.predict([X_test[col] for col in cat_col])\n\nprint('RMSE', mean_squared_error(y_test, emb_pred) ** 0.5)",
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": "__________________________________________________________________________________________________\nLayer (type)                    Output Shape         Param #     Connected to                     \n==================================================================================================\ninput_1 (InputLayer)            (None, 1)            0                                            \n__________________________________________________________________________________________________\ninput_2 (InputLayer)            (None, 1)            0                                            \n__________________________________________________________________________________________________\ninput_3 (InputLayer)            (None, 1)            0                                            \n__________________________________________________________________________________________________\ninput_4 (InputLayer)            (None, 1)            0                                            \n__________________________________________________________________________________________________\ninput_5 (InputLayer)            (None, 1)            0                                            \n__________________________________________________________________________________________________\nembedding_1 (Embedding)         (None, 1, 2)         10          input_1[0][0]                    \n__________________________________________________________________________________________________\nembedding_2 (Embedding)         (None, 1, 1)         3           input_2[0][0]                    \n__________________________________________________________________________________________________\nembedding_3 (Embedding)         (None, 1, 1)         2           input_3[0][0]                    \n__________________________________________________________________________________________________\nembedding_4 (Embedding)         (None, 1, 3)         24          input_4[0][0]                    \n__________________________________________________________________________________________________\nembedding_5 (Embedding)         (None, 1, 4)         48          input_5[0][0]                    \n__________________________________________________________________________________________________\nconcatenate_1 (Concatenate)     (None, 1, 11)        0           embedding_1[0][0]                \n                                                                 embedding_2[0][0]                \n                                                                 embedding_3[0][0]                \n                                                                 embedding_4[0][0]                \n                                                                 embedding_5[0][0]                \n__________________________________________________________________________________________________\nflatten_1 (Flatten)             (None, 11)           0           concatenate_1[0][0]              \n__________________________________________________________________________________________________\nbatch_normalization_1 (BatchNor (None, 11)           44          flatten_1[0][0]                  \n__________________________________________________________________________________________________\ndense_1 (Dense)                 (None, 10)           120         batch_normalization_1[0][0]      \n__________________________________________________________________________________________________\ndense_2 (Dense)                 (None, 10)           110         dense_1[0][0]                    \n__________________________________________________________________________________________________\ndropout_1 (Dropout)             (None, 10)           0           dense_2[0][0]                    \n__________________________________________________________________________________________________\nbatch_normalization_2 (BatchNor (None, 10)           40          dropout_1[0][0]                  \n__________________________________________________________________________________________________\ndense_3 (Dense)                 (None, 10)           110         batch_normalization_2[0][0]      \n__________________________________________________________________________________________________\ndense_4 (Dense)                 (None, 10)           110         dense_3[0][0]                    \n__________________________________________________________________________________________________\ndropout_2 (Dropout)             (None, 10)           0           dense_4[0][0]                    \n__________________________________________________________________________________________________\ndense_5 (Dense)                 (None, 1)            11          dropout_2[0][0]                  \n==================================================================================================\nTotal params: 632\nTrainable params: 590\nNon-trainable params: 42\n__________________________________________________________________________________________________\nNone\nEpoch 1/5\n161533/161533 [==============================] - 49s 302us/step - loss: 3.1478\nEpoch 2/5\n161533/161533 [==============================] - 48s 295us/step - loss: 3.1381\nEpoch 3/5\n161533/161533 [==============================] - 47s 291us/step - loss: 3.1363\nEpoch 4/5\n161533/161533 [==============================] - 47s 291us/step - loss: 3.1346\nEpoch 5/5\n161533/161533 [==============================] - 47s 291us/step - loss: 3.1429\nRMSE 3.781394358500744\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "d6870f754588b7ce15a6d200e14018d86272dd79"
      },
      "cell_type": "code",
      "source": "X_train.head()",
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 17,
          "data": {
            "text/plain": "       first_active_month         ...         new_month_diff_mean\n165743         2017-06-01         ...                    0.539855\n119952         2017-11-01         ...                    0.532234\n89339          2017-09-01         ...                    0.521739\n25589          2014-05-01         ...                    0.565217\n162026         2017-10-01         ...                    0.527950\n\n[5 rows x 56 columns]",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>first_active_month</th>\n      <th>card_id</th>\n      <th>feature_1</th>\n      <th>feature_2</th>\n      <th>feature_3</th>\n      <th>year</th>\n      <th>month</th>\n      <th>elapsed_time</th>\n      <th>history_trx_count</th>\n      <th>history_merchant_id_nunique</th>\n      <th>history_merchant_category_id_nunique</th>\n      <th>history_state_id_nunique</th>\n      <th>history_city_id_nunique</th>\n      <th>history_subsector_id_nunique</th>\n      <th>history_purchase_amount_sum</th>\n      <th>history_purchase_amount_mean</th>\n      <th>history_purchase_amount_max</th>\n      <th>history_purchase_amount_min</th>\n      <th>history_purchase_amount_std</th>\n      <th>history_installments_sum</th>\n      <th>history_installments_mean</th>\n      <th>history_installments_max</th>\n      <th>history_installments_min</th>\n      <th>history_installments_std</th>\n      <th>history_purchase_date_ptp</th>\n      <th>history_purchase_date_min</th>\n      <th>history_purchase_date_max</th>\n      <th>history_month_lag_mean</th>\n      <th>history_month_lag_max</th>\n      <th>history_month_lag_min</th>\n      <th>history_month_lag_std</th>\n      <th>history_month_diff_mean</th>\n      <th>new_trx_count</th>\n      <th>new_merchant_id_nunique</th>\n      <th>new_merchant_category_id_nunique</th>\n      <th>new_state_id_nunique</th>\n      <th>new_city_id_nunique</th>\n      <th>new_subsector_id_nunique</th>\n      <th>new_purchase_amount_sum</th>\n      <th>new_purchase_amount_mean</th>\n      <th>new_purchase_amount_max</th>\n      <th>new_purchase_amount_min</th>\n      <th>new_purchase_amount_std</th>\n      <th>new_installments_sum</th>\n      <th>new_installments_mean</th>\n      <th>new_installments_max</th>\n      <th>new_installments_min</th>\n      <th>new_installments_std</th>\n      <th>new_purchase_date_ptp</th>\n      <th>new_purchase_date_min</th>\n      <th>new_purchase_date_max</th>\n      <th>new_month_lag_mean</th>\n      <th>new_month_lag_max</th>\n      <th>new_month_lag_min</th>\n      <th>new_month_lag_std</th>\n      <th>new_month_diff_mean</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>165743</th>\n      <td>2017-06-01</td>\n      <td>C_ID_f9f784f2e2</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>6</td>\n      <td>8</td>\n      <td>0.892732</td>\n      <td>0.918213</td>\n      <td>0.798489</td>\n      <td>0.574468</td>\n      <td>0.947368</td>\n      <td>0.878788</td>\n      <td>0.454545</td>\n      <td>0.999679</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>0.999544</td>\n      <td>1.000000</td>\n      <td>0.874071</td>\n      <td>0.975929</td>\n      <td>0.989990</td>\n      <td>1.000000</td>\n      <td>0.996176</td>\n      <td>0.387759</td>\n      <td>0.551730</td>\n      <td>0.000438</td>\n      <td>0.264798</td>\n      <td>0.000000</td>\n      <td>0.583333</td>\n      <td>0.642373</td>\n      <td>0.943269</td>\n      <td>0.881818</td>\n      <td>0.881818</td>\n      <td>0.780488</td>\n      <td>0.866667</td>\n      <td>0.862069</td>\n      <td>0.68</td>\n      <td>0.651855</td>\n      <td>0.993164</td>\n      <td>0.995117</td>\n      <td>0.993652</td>\n      <td>0.978516</td>\n      <td>0.981188</td>\n      <td>0.941513</td>\n      <td>0.997</td>\n      <td>0.846154</td>\n      <td>0.993089</td>\n      <td>0.066801</td>\n      <td>0.003361</td>\n      <td>0.000092</td>\n      <td>0.222222</td>\n      <td>0.0</td>\n      <td>0.333333</td>\n      <td>0.125792</td>\n      <td>0.539855</td>\n    </tr>\n    <tr>\n      <th>119952</th>\n      <td>2017-11-01</td>\n      <td>C_ID_c36d60df2c</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>6</td>\n      <td>2</td>\n      <td>0.959720</td>\n      <td>0.970790</td>\n      <td>0.899244</td>\n      <td>0.744681</td>\n      <td>0.842105</td>\n      <td>0.939394</td>\n      <td>0.575758</td>\n      <td>0.999661</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>0.999528</td>\n      <td>1.000000</td>\n      <td>0.960363</td>\n      <td>0.978846</td>\n      <td>0.996997</td>\n      <td>1.000000</td>\n      <td>0.998540</td>\n      <td>0.774618</td>\n      <td>0.110719</td>\n      <td>0.006458</td>\n      <td>0.106003</td>\n      <td>0.000000</td>\n      <td>0.166667</td>\n      <td>0.863084</td>\n      <td>0.959328</td>\n      <td>0.727273</td>\n      <td>0.727273</td>\n      <td>0.463415</td>\n      <td>0.600000</td>\n      <td>0.793103</td>\n      <td>0.44</td>\n      <td>0.645996</td>\n      <td>0.983398</td>\n      <td>0.918945</td>\n      <td>0.993652</td>\n      <td>0.953613</td>\n      <td>0.952475</td>\n      <td>0.931268</td>\n      <td>0.989</td>\n      <td>0.846154</td>\n      <td>0.985507</td>\n      <td>0.040831</td>\n      <td>0.003376</td>\n      <td>0.000016</td>\n      <td>0.218391</td>\n      <td>0.0</td>\n      <td>0.333333</td>\n      <td>0.130854</td>\n      <td>0.532234</td>\n    </tr>\n    <tr>\n      <th>89339</th>\n      <td>2017-09-01</td>\n      <td>C_ID_42699e8b0c</td>\n      <td>3</td>\n      <td>0</td>\n      <td>0</td>\n      <td>6</td>\n      <td>11</td>\n      <td>0.933012</td>\n      <td>0.988316</td>\n      <td>0.989924</td>\n      <td>0.946809</td>\n      <td>0.947368</td>\n      <td>0.984848</td>\n      <td>0.878788</td>\n      <td>0.999656</td>\n      <td>1.000000</td>\n      <td>0.999999</td>\n      <td>0.999846</td>\n      <td>1.000000</td>\n      <td>0.970273</td>\n      <td>0.969471</td>\n      <td>0.987988</td>\n      <td>0.818182</td>\n      <td>0.990392</td>\n      <td>0.617788</td>\n      <td>0.285263</td>\n      <td>0.000077</td>\n      <td>0.217673</td>\n      <td>0.000000</td>\n      <td>0.333333</td>\n      <td>0.744954</td>\n      <td>0.976496</td>\n      <td>0.972727</td>\n      <td>0.972727</td>\n      <td>0.926829</td>\n      <td>0.800000</td>\n      <td>0.896552</td>\n      <td>0.88</td>\n      <td>0.589355</td>\n      <td>0.944824</td>\n      <td>0.959961</td>\n      <td>0.958008</td>\n      <td>0.961914</td>\n      <td>0.983168</td>\n      <td>0.817522</td>\n      <td>0.987</td>\n      <td>1.000000</td>\n      <td>0.945342</td>\n      <td>0.771859</td>\n      <td>0.002342</td>\n      <td>0.001544</td>\n      <td>0.166667</td>\n      <td>0.0</td>\n      <td>0.333333</td>\n      <td>0.000000</td>\n      <td>0.521739</td>\n    </tr>\n    <tr>\n      <th>25589</th>\n      <td>2014-05-01</td>\n      <td>C_ID_750614dd76</td>\n      <td>2</td>\n      <td>2</td>\n      <td>1</td>\n      <td>3</td>\n      <td>7</td>\n      <td>0.399299</td>\n      <td>0.992440</td>\n      <td>0.959698</td>\n      <td>0.882979</td>\n      <td>0.947368</td>\n      <td>0.954545</td>\n      <td>0.696970</td>\n      <td>0.999655</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>0.999913</td>\n      <td>1.000000</td>\n      <td>0.996284</td>\n      <td>0.991346</td>\n      <td>1.000000</td>\n      <td>0.909091</td>\n      <td>1.000000</td>\n      <td>0.218255</td>\n      <td>0.825824</td>\n      <td>0.072956</td>\n      <td>0.424262</td>\n      <td>0.090909</td>\n      <td>0.833333</td>\n      <td>0.531786</td>\n      <td>0.942308</td>\n      <td>0.981818</td>\n      <td>0.981818</td>\n      <td>0.951220</td>\n      <td>0.866667</td>\n      <td>0.931034</td>\n      <td>0.92</td>\n      <td>0.610352</td>\n      <td>0.993652</td>\n      <td>0.996582</td>\n      <td>0.993652</td>\n      <td>1.000000</td>\n      <td>0.994059</td>\n      <td>0.971926</td>\n      <td>0.999</td>\n      <td>0.923077</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>0.000013</td>\n      <td>0.000014</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>0.565217</td>\n    </tr>\n    <tr>\n      <th>162026</th>\n      <td>2017-10-01</td>\n      <td>C_ID_18d2ec30fc</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>6</td>\n      <td>1</td>\n      <td>0.946147</td>\n      <td>0.967698</td>\n      <td>0.889169</td>\n      <td>0.755319</td>\n      <td>0.842105</td>\n      <td>0.924242</td>\n      <td>0.575758</td>\n      <td>0.999644</td>\n      <td>0.999997</td>\n      <td>0.999998</td>\n      <td>0.999564</td>\n      <td>0.999998</td>\n      <td>0.922378</td>\n      <td>0.968039</td>\n      <td>0.989990</td>\n      <td>1.000000</td>\n      <td>0.992489</td>\n      <td>0.675289</td>\n      <td>0.231007</td>\n      <td>0.011469</td>\n      <td>0.142854</td>\n      <td>0.000000</td>\n      <td>0.250000</td>\n      <td>0.812234</td>\n      <td>0.943910</td>\n      <td>0.863636</td>\n      <td>0.863636</td>\n      <td>0.682927</td>\n      <td>0.733333</td>\n      <td>0.758621</td>\n      <td>0.48</td>\n      <td>0.617676</td>\n      <td>0.981445</td>\n      <td>0.958008</td>\n      <td>0.994629</td>\n      <td>0.958496</td>\n      <td>0.964356</td>\n      <td>0.911769</td>\n      <td>0.987</td>\n      <td>1.000000</td>\n      <td>0.976078</td>\n      <td>0.191936</td>\n      <td>0.003150</td>\n      <td>0.000319</td>\n      <td>0.166667</td>\n      <td>0.0</td>\n      <td>0.333333</td>\n      <td>0.110264</td>\n      <td>0.527950</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "_uuid": "8991d93bb0e46777090170c7b8e3669d7a2cc490"
      },
      "cell_type": "markdown",
      "source": "# Use the embeddings we got as a “feature extractor” for a LGBMRegressor model"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "181de76369ffd9f6e102904f355c0a59cfdb9b38"
      },
      "cell_type": "code",
      "source": "emb_output = emb_model.layers[11].output\n\nfeature_model = Model(emb_model.input, emb_output)\n\nfeature_model.compile(optimizer = \"RMSProp\", loss = root_mean_squared_error)\nprint(feature_model.summary())\n\nfeaturs = feature_model.predict([X_train[col] for col in cat_col])\nfeatures_test = feature_model.predict([X_test[col] for col in cat_col])\n\nlgb_model = lgb.LGBMRegressor()\nlgb_model.fit(featurs, y_train.values)\n\nlgb_pred = lgb_model.predict(features_test)\n\nprint('RMSE', mean_squared_error(y_test, lgb_pred) ** 0.5)",
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": "__________________________________________________________________________________________________\nLayer (type)                    Output Shape         Param #     Connected to                     \n==================================================================================================\ninput_1 (InputLayer)            (None, 1)            0                                            \n__________________________________________________________________________________________________\ninput_2 (InputLayer)            (None, 1)            0                                            \n__________________________________________________________________________________________________\ninput_3 (InputLayer)            (None, 1)            0                                            \n__________________________________________________________________________________________________\ninput_4 (InputLayer)            (None, 1)            0                                            \n__________________________________________________________________________________________________\ninput_5 (InputLayer)            (None, 1)            0                                            \n__________________________________________________________________________________________________\nembedding_1 (Embedding)         (None, 1, 2)         10          input_1[0][0]                    \n__________________________________________________________________________________________________\nembedding_2 (Embedding)         (None, 1, 1)         3           input_2[0][0]                    \n__________________________________________________________________________________________________\nembedding_3 (Embedding)         (None, 1, 1)         2           input_3[0][0]                    \n__________________________________________________________________________________________________\nembedding_4 (Embedding)         (None, 1, 3)         24          input_4[0][0]                    \n__________________________________________________________________________________________________\nembedding_5 (Embedding)         (None, 1, 4)         48          input_5[0][0]                    \n__________________________________________________________________________________________________\nconcatenate_1 (Concatenate)     (None, 1, 11)        0           embedding_1[0][0]                \n                                                                 embedding_2[0][0]                \n                                                                 embedding_3[0][0]                \n                                                                 embedding_4[0][0]                \n                                                                 embedding_5[0][0]                \n__________________________________________________________________________________________________\nflatten_1 (Flatten)             (None, 11)           0           concatenate_1[0][0]              \n==================================================================================================\nTotal params: 87\nTrainable params: 87\nNon-trainable params: 0\n__________________________________________________________________________________________________\nNone\nRMSE 3.75591792298005\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "8b0fb7a0d8d2bbfd0663d857fcae7cfb6a2b5320"
      },
      "cell_type": "code",
      "source": "X_train.head()",
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 19,
          "data": {
            "text/plain": "       first_active_month         ...         new_month_diff_mean\n165743         2017-06-01         ...                    0.539855\n119952         2017-11-01         ...                    0.532234\n89339          2017-09-01         ...                    0.521739\n25589          2014-05-01         ...                    0.565217\n162026         2017-10-01         ...                    0.527950\n\n[5 rows x 56 columns]",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>first_active_month</th>\n      <th>card_id</th>\n      <th>feature_1</th>\n      <th>feature_2</th>\n      <th>feature_3</th>\n      <th>year</th>\n      <th>month</th>\n      <th>elapsed_time</th>\n      <th>history_trx_count</th>\n      <th>history_merchant_id_nunique</th>\n      <th>history_merchant_category_id_nunique</th>\n      <th>history_state_id_nunique</th>\n      <th>history_city_id_nunique</th>\n      <th>history_subsector_id_nunique</th>\n      <th>history_purchase_amount_sum</th>\n      <th>history_purchase_amount_mean</th>\n      <th>history_purchase_amount_max</th>\n      <th>history_purchase_amount_min</th>\n      <th>history_purchase_amount_std</th>\n      <th>history_installments_sum</th>\n      <th>history_installments_mean</th>\n      <th>history_installments_max</th>\n      <th>history_installments_min</th>\n      <th>history_installments_std</th>\n      <th>history_purchase_date_ptp</th>\n      <th>history_purchase_date_min</th>\n      <th>history_purchase_date_max</th>\n      <th>history_month_lag_mean</th>\n      <th>history_month_lag_max</th>\n      <th>history_month_lag_min</th>\n      <th>history_month_lag_std</th>\n      <th>history_month_diff_mean</th>\n      <th>new_trx_count</th>\n      <th>new_merchant_id_nunique</th>\n      <th>new_merchant_category_id_nunique</th>\n      <th>new_state_id_nunique</th>\n      <th>new_city_id_nunique</th>\n      <th>new_subsector_id_nunique</th>\n      <th>new_purchase_amount_sum</th>\n      <th>new_purchase_amount_mean</th>\n      <th>new_purchase_amount_max</th>\n      <th>new_purchase_amount_min</th>\n      <th>new_purchase_amount_std</th>\n      <th>new_installments_sum</th>\n      <th>new_installments_mean</th>\n      <th>new_installments_max</th>\n      <th>new_installments_min</th>\n      <th>new_installments_std</th>\n      <th>new_purchase_date_ptp</th>\n      <th>new_purchase_date_min</th>\n      <th>new_purchase_date_max</th>\n      <th>new_month_lag_mean</th>\n      <th>new_month_lag_max</th>\n      <th>new_month_lag_min</th>\n      <th>new_month_lag_std</th>\n      <th>new_month_diff_mean</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>165743</th>\n      <td>2017-06-01</td>\n      <td>C_ID_f9f784f2e2</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>6</td>\n      <td>8</td>\n      <td>0.892732</td>\n      <td>0.918213</td>\n      <td>0.798489</td>\n      <td>0.574468</td>\n      <td>0.947368</td>\n      <td>0.878788</td>\n      <td>0.454545</td>\n      <td>0.999679</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>0.999544</td>\n      <td>1.000000</td>\n      <td>0.874071</td>\n      <td>0.975929</td>\n      <td>0.989990</td>\n      <td>1.000000</td>\n      <td>0.996176</td>\n      <td>0.387759</td>\n      <td>0.551730</td>\n      <td>0.000438</td>\n      <td>0.264798</td>\n      <td>0.000000</td>\n      <td>0.583333</td>\n      <td>0.642373</td>\n      <td>0.943269</td>\n      <td>0.881818</td>\n      <td>0.881818</td>\n      <td>0.780488</td>\n      <td>0.866667</td>\n      <td>0.862069</td>\n      <td>0.68</td>\n      <td>0.651855</td>\n      <td>0.993164</td>\n      <td>0.995117</td>\n      <td>0.993652</td>\n      <td>0.978516</td>\n      <td>0.981188</td>\n      <td>0.941513</td>\n      <td>0.997</td>\n      <td>0.846154</td>\n      <td>0.993089</td>\n      <td>0.066801</td>\n      <td>0.003361</td>\n      <td>0.000092</td>\n      <td>0.222222</td>\n      <td>0.0</td>\n      <td>0.333333</td>\n      <td>0.125792</td>\n      <td>0.539855</td>\n    </tr>\n    <tr>\n      <th>119952</th>\n      <td>2017-11-01</td>\n      <td>C_ID_c36d60df2c</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>6</td>\n      <td>2</td>\n      <td>0.959720</td>\n      <td>0.970790</td>\n      <td>0.899244</td>\n      <td>0.744681</td>\n      <td>0.842105</td>\n      <td>0.939394</td>\n      <td>0.575758</td>\n      <td>0.999661</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>0.999528</td>\n      <td>1.000000</td>\n      <td>0.960363</td>\n      <td>0.978846</td>\n      <td>0.996997</td>\n      <td>1.000000</td>\n      <td>0.998540</td>\n      <td>0.774618</td>\n      <td>0.110719</td>\n      <td>0.006458</td>\n      <td>0.106003</td>\n      <td>0.000000</td>\n      <td>0.166667</td>\n      <td>0.863084</td>\n      <td>0.959328</td>\n      <td>0.727273</td>\n      <td>0.727273</td>\n      <td>0.463415</td>\n      <td>0.600000</td>\n      <td>0.793103</td>\n      <td>0.44</td>\n      <td>0.645996</td>\n      <td>0.983398</td>\n      <td>0.918945</td>\n      <td>0.993652</td>\n      <td>0.953613</td>\n      <td>0.952475</td>\n      <td>0.931268</td>\n      <td>0.989</td>\n      <td>0.846154</td>\n      <td>0.985507</td>\n      <td>0.040831</td>\n      <td>0.003376</td>\n      <td>0.000016</td>\n      <td>0.218391</td>\n      <td>0.0</td>\n      <td>0.333333</td>\n      <td>0.130854</td>\n      <td>0.532234</td>\n    </tr>\n    <tr>\n      <th>89339</th>\n      <td>2017-09-01</td>\n      <td>C_ID_42699e8b0c</td>\n      <td>3</td>\n      <td>0</td>\n      <td>0</td>\n      <td>6</td>\n      <td>11</td>\n      <td>0.933012</td>\n      <td>0.988316</td>\n      <td>0.989924</td>\n      <td>0.946809</td>\n      <td>0.947368</td>\n      <td>0.984848</td>\n      <td>0.878788</td>\n      <td>0.999656</td>\n      <td>1.000000</td>\n      <td>0.999999</td>\n      <td>0.999846</td>\n      <td>1.000000</td>\n      <td>0.970273</td>\n      <td>0.969471</td>\n      <td>0.987988</td>\n      <td>0.818182</td>\n      <td>0.990392</td>\n      <td>0.617788</td>\n      <td>0.285263</td>\n      <td>0.000077</td>\n      <td>0.217673</td>\n      <td>0.000000</td>\n      <td>0.333333</td>\n      <td>0.744954</td>\n      <td>0.976496</td>\n      <td>0.972727</td>\n      <td>0.972727</td>\n      <td>0.926829</td>\n      <td>0.800000</td>\n      <td>0.896552</td>\n      <td>0.88</td>\n      <td>0.589355</td>\n      <td>0.944824</td>\n      <td>0.959961</td>\n      <td>0.958008</td>\n      <td>0.961914</td>\n      <td>0.983168</td>\n      <td>0.817522</td>\n      <td>0.987</td>\n      <td>1.000000</td>\n      <td>0.945342</td>\n      <td>0.771859</td>\n      <td>0.002342</td>\n      <td>0.001544</td>\n      <td>0.166667</td>\n      <td>0.0</td>\n      <td>0.333333</td>\n      <td>0.000000</td>\n      <td>0.521739</td>\n    </tr>\n    <tr>\n      <th>25589</th>\n      <td>2014-05-01</td>\n      <td>C_ID_750614dd76</td>\n      <td>2</td>\n      <td>2</td>\n      <td>1</td>\n      <td>3</td>\n      <td>7</td>\n      <td>0.399299</td>\n      <td>0.992440</td>\n      <td>0.959698</td>\n      <td>0.882979</td>\n      <td>0.947368</td>\n      <td>0.954545</td>\n      <td>0.696970</td>\n      <td>0.999655</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>0.999913</td>\n      <td>1.000000</td>\n      <td>0.996284</td>\n      <td>0.991346</td>\n      <td>1.000000</td>\n      <td>0.909091</td>\n      <td>1.000000</td>\n      <td>0.218255</td>\n      <td>0.825824</td>\n      <td>0.072956</td>\n      <td>0.424262</td>\n      <td>0.090909</td>\n      <td>0.833333</td>\n      <td>0.531786</td>\n      <td>0.942308</td>\n      <td>0.981818</td>\n      <td>0.981818</td>\n      <td>0.951220</td>\n      <td>0.866667</td>\n      <td>0.931034</td>\n      <td>0.92</td>\n      <td>0.610352</td>\n      <td>0.993652</td>\n      <td>0.996582</td>\n      <td>0.993652</td>\n      <td>1.000000</td>\n      <td>0.994059</td>\n      <td>0.971926</td>\n      <td>0.999</td>\n      <td>0.923077</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>0.000013</td>\n      <td>0.000014</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>0.565217</td>\n    </tr>\n    <tr>\n      <th>162026</th>\n      <td>2017-10-01</td>\n      <td>C_ID_18d2ec30fc</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>6</td>\n      <td>1</td>\n      <td>0.946147</td>\n      <td>0.967698</td>\n      <td>0.889169</td>\n      <td>0.755319</td>\n      <td>0.842105</td>\n      <td>0.924242</td>\n      <td>0.575758</td>\n      <td>0.999644</td>\n      <td>0.999997</td>\n      <td>0.999998</td>\n      <td>0.999564</td>\n      <td>0.999998</td>\n      <td>0.922378</td>\n      <td>0.968039</td>\n      <td>0.989990</td>\n      <td>1.000000</td>\n      <td>0.992489</td>\n      <td>0.675289</td>\n      <td>0.231007</td>\n      <td>0.011469</td>\n      <td>0.142854</td>\n      <td>0.000000</td>\n      <td>0.250000</td>\n      <td>0.812234</td>\n      <td>0.943910</td>\n      <td>0.863636</td>\n      <td>0.863636</td>\n      <td>0.682927</td>\n      <td>0.733333</td>\n      <td>0.758621</td>\n      <td>0.48</td>\n      <td>0.617676</td>\n      <td>0.981445</td>\n      <td>0.958008</td>\n      <td>0.994629</td>\n      <td>0.958496</td>\n      <td>0.964356</td>\n      <td>0.911769</td>\n      <td>0.987</td>\n      <td>1.000000</td>\n      <td>0.976078</td>\n      <td>0.191936</td>\n      <td>0.003150</td>\n      <td>0.000319</td>\n      <td>0.166667</td>\n      <td>0.0</td>\n      <td>0.333333</td>\n      <td>0.110264</td>\n      <td>0.527950</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "_uuid": "1f9502dc4a042bb0c1e4eb1026ab1ba72fa582e1"
      },
      "cell_type": "markdown",
      "source": "# Add the rest of the features "
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "093c9733924a4ec78a336587be18fa3791dcac6b"
      },
      "cell_type": "code",
      "source": "# define continuous input\ncontinuous_input = Input(shape=(len(numeric_col),)) #train_set_no_nan[numeric_col].shape[1]\n\n# define categorical input                         \nf1_emb = Reshape((2,))(f1_emb)\nf2_emb = Reshape((1,))(f2_emb)\nf3_emb = Reshape((1,))(f3_emb)\nyear_emb = Reshape((3,))(year_emb)\nmonth_emb = Reshape((4,))(month_emb)\n                         \n#split train set to train and validation set\nX_train_val, X_val, y_train_val, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=6)\n                         \n# define function to create input to model\ndef get_input(data):\n    inp = [data[numeric_col], data['feature_1'], data['feature_2'], data['feature_3'],\n      data['year'], data['month']]\n    return inp",
      "execution_count": 20,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "91e12c16b437a35c5cc063095121613e18ce343a"
      },
      "cell_type": "code",
      "source": "x = concatenate([continuous_input,f1_emb,f2_emb,f3_emb,year_emb,month_emb])\nx = BatchNormalization()(x)\nx = Dense(10,activation='relu')(x)\nx = Dense(10,activation='relu')(x)\nx = Dropout(0.4)(x)\nx = BatchNormalization()(x)\nx = Dense(10,activation='relu')(x)\nx = Dense(10,activation='relu')(x)\nx = Dropout(0.7)(x)\nx = Dense(1, activation='linear')(x)\nemb_cont_model = Model([continuous_input,f1_inp,f2_inp,f3_inp,year_inp,month_inp],x)\n\nrmsprop_opt = RMSprop(lr=0.005)\nemb_cont_model.compile(optimizer = rmsprop_opt, loss = root_mean_squared_error)\n\nprint(emb_cont_model.summary())\n\ndef set_callbacks(description='run1',patience=15,tb_base_logdir='./logs/'):\n    cp = ModelCheckpoint('best_model_weights_{}.h5'.format(description),save_best_only=True)\n    es = EarlyStopping(patience=patience,monitor='val_loss')\n    rlop = ReduceLROnPlateau(patience=5)   \n    tb = TensorBoard(log_dir='{}{}'.format(tb_base_logdir,description))\n    cb = [cp,es,tb,rlop]\n    return cb\n\nhistory = emb_cont_model.fit(get_input(X_train_val), y_train_val, epochs=5, batch_size=16, \n          validation_data=(get_input(X_val), y_val),callbacks=set_callbacks())\n\nemb_cont_pred = emb_cont_model.predict(get_input(X_test))\n\nprint('RMSE', mean_squared_error(y_test, emb_cont_pred) ** 0.5)",
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": "__________________________________________________________________________________________________\nLayer (type)                    Output Shape         Param #     Connected to                     \n==================================================================================================\ninput_1 (InputLayer)            (None, 1)            0                                            \n__________________________________________________________________________________________________\ninput_2 (InputLayer)            (None, 1)            0                                            \n__________________________________________________________________________________________________\ninput_3 (InputLayer)            (None, 1)            0                                            \n__________________________________________________________________________________________________\ninput_4 (InputLayer)            (None, 1)            0                                            \n__________________________________________________________________________________________________\ninput_5 (InputLayer)            (None, 1)            0                                            \n__________________________________________________________________________________________________\nembedding_1 (Embedding)         (None, 1, 2)         10          input_1[0][0]                    \n__________________________________________________________________________________________________\nembedding_2 (Embedding)         (None, 1, 1)         3           input_2[0][0]                    \n__________________________________________________________________________________________________\nembedding_3 (Embedding)         (None, 1, 1)         2           input_3[0][0]                    \n__________________________________________________________________________________________________\nembedding_4 (Embedding)         (None, 1, 3)         24          input_4[0][0]                    \n__________________________________________________________________________________________________\nembedding_5 (Embedding)         (None, 1, 4)         48          input_5[0][0]                    \n__________________________________________________________________________________________________\ninput_6 (InputLayer)            (None, 49)           0                                            \n__________________________________________________________________________________________________\nreshape_1 (Reshape)             (None, 2)            0           embedding_1[0][0]                \n__________________________________________________________________________________________________\nreshape_2 (Reshape)             (None, 1)            0           embedding_2[0][0]                \n__________________________________________________________________________________________________\nreshape_3 (Reshape)             (None, 1)            0           embedding_3[0][0]                \n__________________________________________________________________________________________________\nreshape_4 (Reshape)             (None, 3)            0           embedding_4[0][0]                \n__________________________________________________________________________________________________\nreshape_5 (Reshape)             (None, 4)            0           embedding_5[0][0]                \n__________________________________________________________________________________________________\nconcatenate_2 (Concatenate)     (None, 60)           0           input_6[0][0]                    \n                                                                 reshape_1[0][0]                  \n                                                                 reshape_2[0][0]                  \n                                                                 reshape_3[0][0]                  \n                                                                 reshape_4[0][0]                  \n                                                                 reshape_5[0][0]                  \n__________________________________________________________________________________________________\nbatch_normalization_3 (BatchNor (None, 60)           240         concatenate_2[0][0]              \n__________________________________________________________________________________________________\ndense_6 (Dense)                 (None, 10)           610         batch_normalization_3[0][0]      \n__________________________________________________________________________________________________\ndense_7 (Dense)                 (None, 10)           110         dense_6[0][0]                    \n__________________________________________________________________________________________________\ndropout_3 (Dropout)             (None, 10)           0           dense_7[0][0]                    \n__________________________________________________________________________________________________\nbatch_normalization_4 (BatchNor (None, 10)           40          dropout_3[0][0]                  \n__________________________________________________________________________________________________\ndense_8 (Dense)                 (None, 10)           110         batch_normalization_4[0][0]      \n__________________________________________________________________________________________________\ndense_9 (Dense)                 (None, 10)           110         dense_8[0][0]                    \n__________________________________________________________________________________________________\ndropout_4 (Dropout)             (None, 10)           0           dense_9[0][0]                    \n__________________________________________________________________________________________________\ndense_10 (Dense)                (None, 1)            11          dropout_4[0][0]                  \n==================================================================================================\nTotal params: 1,318\nTrainable params: 1,178\nNon-trainable params: 140\n__________________________________________________________________________________________________\nNone\nTrain on 129226 samples, validate on 32307 samples\nEpoch 1/5\n129226/129226 [==============================] - 85s 656us/step - loss: 2.7766 - val_loss: 2.7824\nEpoch 2/5\n129226/129226 [==============================] - 84s 648us/step - loss: 2.7739 - val_loss: 2.7850\nEpoch 3/5\n129226/129226 [==============================] - 84s 647us/step - loss: 2.7654 - val_loss: 2.7976\nEpoch 4/5\n129226/129226 [==============================] - 84s 649us/step - loss: 2.7658 - val_loss: 2.8001\nEpoch 5/5\n129226/129226 [==============================] - 83s 646us/step - loss: 2.7693 - val_loss: 2.7944\nRMSE 3.7472513997551746\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "_uuid": "18ff8dbe2cfa1484facf5e6001529e6cdc3d9cac"
      },
      "cell_type": "markdown",
      "source": "# Write sample submission file"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "d6b22f5247eccfb3dfee91b65b084e7aae2c9733"
      },
      "cell_type": "code",
      "source": "def write_sample_submission(model):\n    y_pred_sample_submission = model.predict(test_set)\n    sample_sub = pd.DataFrame()\n    sample_sub['card_id'] = test_set['card_id']\n    sample_sub['target'] = y_pred_sample_submission\n    sample_sub.to_csv('sample_submmision.csv', index=False)",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.6",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}