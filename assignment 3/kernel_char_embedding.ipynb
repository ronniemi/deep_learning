{
  "cells": [
    {
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true
      },
      "cell_type": "code",
      "source": "# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\n%matplotlib inline\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom keras.models import Model\nfrom keras import optimizers\nfrom keras.models import Sequential\nfrom keras.layers import LSTM, Input, Embedding, Lambda\nfrom keras.layers.normalization import BatchNormalization\nimport keras.backend as K\n\nimport datetime\nfrom time import time\n\nfrom keras.optimizers import Adadelta\nfrom keras.preprocessing.text import Tokenizer\nfrom keras.preprocessing.sequence import pad_sequences\n\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.model_selection import train_test_split\n\nimport xgboost as xgb\nimport lightgbm as lgb\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "510b1e325351c39896012f8eaae8e870d3cc991a"
      },
      "cell_type": "markdown",
      "source": "# Read the data"
    },
    {
      "metadata": {
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "trusted": true
      },
      "cell_type": "code",
      "source": "train = pd.read_csv('../input/train.csv', encoding=\"ISO-8859-1\")\ntest = pd.read_csv('../input/test.csv', encoding=\"ISO-8859-1\")\nprod_desc = pd.read_csv('../input/product_descriptions.csv', encoding=\"ISO-8859-1\")\n\nprint('train size', train.shape)\nprint('test size', test.shape)\nprint('product description size', prod_desc.shape)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "920a26c0a9ce905505be5ae5a86de6233c8a863e"
      },
      "cell_type": "code",
      "source": "train_size = train.shape[0]\ndf_all = pd.concat((train, test), axis=0, ignore_index=True)\ndf_all = pd.merge(df_all, prod_desc, how='left', on='product_uid')\ndf_all['product_full_info'] = df_all['product_title'] + ' ' + df_all['product_description']\ndf_all.drop(['product_title', 'product_description'], axis=1, inplace=True)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "2b295c37257082cf282bbe3a85bff98a996aa42d"
      },
      "cell_type": "code",
      "source": "df_all.head()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "7b49aaa94c7188202018356fafe950c882945da3"
      },
      "cell_type": "markdown",
      "source": "# Split product_full_info and search_term to chars"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "0ddb5429f76f21507438b4f34f3ff7166cae5621"
      },
      "cell_type": "code",
      "source": "char_to_remove = [' ', '-', '{', '}', '\"', '(', ')', '.', ',', ':', '&','[',']','`','_','\\'', '~', \n                  '\\x80', '\\x81', '\\x84', '\\x89', '\\x8b', '\\x90', '\\x93', '\\x95', '\\x99', '\\x9a', \n                  '\\x9d', '\\xa0', '¡', '¢', 'ª', '°', '²', 'À', 'Â', 'È', 'Ê', 'Ë', 'Ï', 'Ò', 'Û', \n                  'Ü', 'â', 'ã', 'å', 'è', '÷']\n\ndef lower_char(char):\n    if char >= 'A' and char <= 'Z':\n        return char.lower()\n    else:\n        return char\n\ndf_all['product_full_info'] = df_all['product_full_info'].apply(lambda sent: [lower_char(character) for character in sent if character not in char_to_remove])\ndf_all['search_term'] = df_all['search_term'].apply(lambda sent: [lower_char(character) for character in sent if character not in char_to_remove])",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "ebb745dd1dba91ad6eb45fbffbfe3ed714ec525b"
      },
      "cell_type": "code",
      "source": "df_all.head()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "c881f397440d138316eeff52c9be75c77397fe60"
      },
      "cell_type": "markdown",
      "source": "# Get all unique chars to preform lable encoder"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "6264f17c02579ea56a039519931d1815fbf29544"
      },
      "cell_type": "code",
      "source": "prod_all_sentences = df_all['product_full_info']\nsearch_all_sentences = df_all['search_term']\n\nall_unique_chars = np.unique(np.concatenate((prod_all_sentences.append(search_all_sentences).values), axis=None))\nall_unique_chars = np.append(['<uniq>'], all_unique_chars)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "0ea710d85215d52e70835e614b7ced758ff820ea"
      },
      "cell_type": "code",
      "source": "all_unique_chars",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "473df6dae184a3f314280053e42685666fe68731"
      },
      "cell_type": "markdown",
      "source": "# Replace tokens in numbers using lable encoder"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "d2b96a77ef1cf500ffdffdc1441206d50eb28098"
      },
      "cell_type": "code",
      "source": "def token_to_num(data, unique_valus):\n    le = LabelEncoder()\n    le.fit(unique_valus)\n\n    data['product_full_info'] = data['product_full_info'].apply(lambda char_list: le.transform(char_list)) \n    data['search_term'] = data['search_term'].apply(lambda char_list: le.transform(char_list)) \n\n    return data\n\ndf_all = token_to_num(df_all, all_unique_chars)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "73a2a2f6b1a85d932ee2b4971bb8a2522d79330a"
      },
      "cell_type": "code",
      "source": "df_all.head()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "a6b5409fdae553d39ffeb1b427043b1e9ac784a6"
      },
      "cell_type": "markdown",
      "source": "# Check max product description and search term length to know how much padding needed"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "10927cac267775f265e4e9f780303c1ef35a7db8"
      },
      "cell_type": "code",
      "source": "def get_max_length(data):\n    max_len = 0\n    for i in range(0, len(data)):\n        if len(data.iloc[i]) > max_len:\n            max_len = len(data.iloc[i])\n    return max_len\n\nmax_length_prod = get_max_length(df_all['product_full_info'])\nmax_length_search = get_max_length(df_all['search_term'])",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "5542bea070e62a31ab78c7bf1824e612200c7412"
      },
      "cell_type": "code",
      "source": "print('max_length_prod', max_length_prod)\nprint('max_length_search', max_length_search)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "f82542e5b5cf610e021ef916050be642ba6e9ec6"
      },
      "cell_type": "markdown",
      "source": "# Split back to train and test sets"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "83270d27a0452f0b8687c6ab8c8bf96c95cbc41a"
      },
      "cell_type": "code",
      "source": "df_train = df_all.iloc[:train_size]\ndf_test = df_all.iloc[train_size:]\ndf_test.reset_index(inplace=True, drop=True)\n\ny = df_train['relevance']\nX = df_train.drop(['id','relevance'], axis=1)\nX_test = df_test.drop(['id','relevance'], axis=1)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "1e793de501b5746dcf10f717fdce1f51fec7a6c3"
      },
      "cell_type": "markdown",
      "source": "# Split to validation set"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "b4aa25a7e31bf84c69f293ea7a9bfb4eef5b24eb"
      },
      "cell_type": "code",
      "source": "validation_size = int(0.2 * X.shape[0])\nX_train, X_val, y_train, y_val = train_test_split(X, y, test_size=validation_size)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "02a2a6aba6cee3e07e9cbd384ee9f5c4d133d774"
      },
      "cell_type": "code",
      "source": "X_train.head()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "aec1a317979d975f0dfb4070b001c08a07fa5f96"
      },
      "cell_type": "markdown",
      "source": "# Split to two sides:\n1. search_term\n2. product_desctiption + title"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "6de4691d3ddcd891392b27d16a7d506b34eb9cbb"
      },
      "cell_type": "code",
      "source": "X_train = {'left': X_train['product_full_info'], 'right': X_train['search_term']}\nX_val = {'left': X_val['product_full_info'], 'right': X_val['search_term']}\nX_test = {'left': df_test['product_full_info'], 'right': df_test['search_term']}",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "6ca1503154be07b2a1490f90d48e814016ac6cf5"
      },
      "cell_type": "code",
      "source": "# Convert labels to their numpy representations\ny_train = y_train.values\ny_val = y_val.values",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "99022b59ca422f8d72a94d4bd61c86278abccfaa"
      },
      "cell_type": "markdown",
      "source": "# Add zero padding to each char list in size of max_length"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "91a87b5b04f00d0019397d4e6df12c9bf0a9a50d"
      },
      "cell_type": "code",
      "source": "for dataset in [X_train, X_val, X_test]:\n    dataset['left'] = pad_sequences(dataset['left'], maxlen=max_length_prod)\n    dataset['right'] = pad_sequences(dataset['right'], maxlen=max_length_search)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "5c858b573d324d8cb59a62246e4339d84c7af3d8"
      },
      "cell_type": "code",
      "source": "print(X_train['left'].shape)\nprint(X_train['right'].shape)\nprint(y_train.shape)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "e88a1554afea52cd69c63ff69c975d42037271ff"
      },
      "cell_type": "markdown",
      "source": "# Build the model"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "15be4109a7cdbfef3f801cfec38eb0fe0fe31a94"
      },
      "cell_type": "code",
      "source": "# Model variables\nn_hidden = 50\ngradient_clipping_norm = 1.25\nbatch_size = 64\nn_epoch = 2\nembedding_dim = 5\n\n# Helper function for the similarity estimate of the LSTMs outputs\ndef exponent_neg_manhattan_distance(left, right):\n    result = K.exp(-K.sum(K.abs(left-right), axis=1, keepdims=True))\n    return (result * 2) + 1\n\n# input layer\nleft_input = Input(shape=(max_length_prod,), dtype='int32')\nright_input = Input(shape=(max_length_search,), dtype='int32')\n\n# embedding layers\nembedding_layer_prod = Embedding(input_dim=len(all_unique_chars), output_dim=embedding_dim, \n                                 input_length=max_length_prod)\nembedding_layer_search = Embedding(input_dim=len(all_unique_chars), output_dim=embedding_dim, \n                                   input_length=max_length_search)\n\n# Embedded version of the inputs\nencoded_left = embedding_layer_prod(left_input)\nencoded_right = embedding_layer_search(right_input)\n\n# LSTM layer\nshared_lstm = LSTM(n_hidden)\nleft_output = shared_lstm(encoded_left)\nright_output = shared_lstm(encoded_right)\n\n# Calculates the distance as defined by the MaLSTM model\nmalstm_distance = Lambda(function=lambda x: exponent_neg_manhattan_distance(x[0], x[1]),\n                         output_shape=lambda x: (x[0][0], 1))([left_output, right_output])\n\n# Pack it all up into a model\nsiamese_model = Model([left_input, right_input], [malstm_distance])\n\n# Adadelta optimizer, with gradient clipping by norm\noptimizer = Adadelta(clipnorm=gradient_clipping_norm)\n\n# colmpiling\nsiamese_model.compile(loss='mean_squared_error', optimizer=optimizer, metrics=['accuracy'])\n\ntraining_start_time = time()\nhistory = siamese_model.fit([X_train['left'], X_train['right']], y_train, batch_size=batch_size, epochs=n_epoch,\n                            validation_data=([X_val['left'], X_val['right']], y_val))\nprint(datetime.timedelta(seconds=time()-training_start_time))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "1a1001405110fd716d8f21b86ea30ffe648634f6"
      },
      "cell_type": "code",
      "source": "# Plot accuracy\nplt.plot(malstm_trained.history['acc'])\nplt.plot(malstm_trained.history['val_acc'])\nplt.title('Model Accuracy')\nplt.ylabel('Accuracy')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Validation'], loc='upper left')\nplt.show()\n\n# Plot loss\nplt.plot(malstm_trained.history['loss'])\nplt.plot(malstm_trained.history['val_loss'])\nplt.title('Model Loss')\nplt.ylabel('Loss')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Validation'], loc='upper right')\nplt.show()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "317e387c1c60b10c9714bad2e7a976ffb66d3d71"
      },
      "cell_type": "code",
      "source": "pred = siamese_model.predict(X_test)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "d86f9f54f15b5861e9ea453bbf886c809a0fb31e"
      },
      "cell_type": "code",
      "source": "sample_sub = pd.DataFrame()\nsample_sub['id'] = test['id']\nsample_sub['relevance'] = pred",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "4ec48d09772a06ec47042d24ce9cea5dfa63ecee"
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.6",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}